{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjVq9Nt59OL4qXDZ/TLm1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnimeshGalande/NLP/blob/master/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBjFLsI3IaVm"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ_HaAqMcQK3",
        "outputId": "ff280e64-63ce-4f40-fa18-ae0a0015e523"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Ugvqrxf-KJuA",
        "outputId": "1472790c-0e1c-4674-cb64-78d899954df4"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-264d62d1-6406-4c72-bc32-c1706fa30208\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-264d62d1-6406-4c72-bc32-c1706fa30208\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "7E6NF8mNIx9Q",
        "outputId": "4e043571-1a4c-4c07-fe93-adea30b723f0"
      },
      "source": [
        "Data =  pd.read_csv('Churn_Modelling.csv')\n",
        "X = Data.iloc[:, 3:13]\n",
        "y = Data.iloc[:, 13]\n",
        "Data"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0             1    15634602   Hargrave  ...               1       101348.88      1\n",
              "1             2    15647311       Hill  ...               1       112542.58      0\n",
              "2             3    15619304       Onio  ...               0       113931.57      1\n",
              "3             4    15701354       Boni  ...               0        93826.63      0\n",
              "4             5    15737888   Mitchell  ...               1        79084.10      0\n",
              "...         ...         ...        ...  ...             ...             ...    ...\n",
              "9995       9996    15606229   Obijiaku  ...               0        96270.64      0\n",
              "9996       9997    15569892  Johnstone  ...               1       101699.77      0\n",
              "9997       9998    15584532        Liu  ...               1        42085.58      1\n",
              "9998       9999    15682355  Sabbatini  ...               0        92888.52      1\n",
              "9999      10000    15628319     Walker  ...               0        38190.78      0\n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_qheodVLLrG"
      },
      "source": [
        "Geography = pd.get_dummies(X['Geography'])\n",
        "Gender = pd.get_dummies(X['Gender'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRWUGrmlMFTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "654aedcc-808a-48d9-e67f-1a74708bfc72"
      },
      "source": [
        "X=pd.concat([X,Geography,Gender],axis=1)\n",
        "## Drop Unnecessary columns\n",
        "X=X.drop(['Geography','Gender'],axis=1)\n",
        "X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>France</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Age  Tenure    Balance  ...  Germany  Spain  Female  Male\n",
              "0             619   42       2       0.00  ...        0      0       1     0\n",
              "1             608   41       1   83807.86  ...        0      1       1     0\n",
              "2             502   42       8  159660.80  ...        0      0       1     0\n",
              "3             699   39       1       0.00  ...        0      0       1     0\n",
              "4             850   43       2  125510.82  ...        0      1       1     0\n",
              "...           ...  ...     ...        ...  ...      ...    ...     ...   ...\n",
              "9995          771   39       5       0.00  ...        0      0       0     1\n",
              "9996          516   35      10   57369.61  ...        0      0       0     1\n",
              "9997          709   36       7       0.00  ...        0      0       1     0\n",
              "9998          772   42       3   75075.31  ...        1      0       0     1\n",
              "9999          792   28       4  130142.79  ...        0      0       1     0\n",
              "\n",
              "[10000 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I8iR-ifNjcC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3vS_Ds3OehE"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWUz0fOFQfNf"
      },
      "source": [
        "#feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsgI1b84PLSQ"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import ReLU,LeakyReLU,ELU\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZggivBcPM_C"
      },
      "source": [
        "classifier = Sequential()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S94jrhZGRf3d"
      },
      "source": [
        "classifier.add(Dense(units=6,activation='relu',kernel_initializer='he_uniform',input_dim=13))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-wwsgWHe3ll"
      },
      "source": [
        "#second layer\n",
        "classifier.add(Dense(units=6,activation='relu',kernel_initializer='he_uniform'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St_gG3qcfqTL"
      },
      "source": [
        "#output layer\n",
        "classifier.add(Dense(units=1,activation='sigmoid',kernel_initializer='glorot_uniform'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rk-YGLRgBPJ",
        "outputId": "7b28cc54-eddf-42d4-a345-42d291ddd648"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 6)                 84        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 133\n",
            "Trainable params: 133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCIo6ynxgTVZ"
      },
      "source": [
        "classifier.compile(optimizer='Adamax',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDaWkoMovP5D",
        "outputId": "719240c6-24f8-4fd7-8d4d-218425667829"
      },
      "source": [
        "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 2s 2ms/step - loss: 0.6314 - accuracy: 0.7557 - val_loss: 0.5784 - val_accuracy: 0.7959\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5771 - accuracy: 0.7963 - val_loss: 0.5437 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5499 - accuracy: 0.7934 - val_loss: 0.5187 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7961 - val_loss: 0.5011 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5051 - accuracy: 0.7881 - val_loss: 0.4872 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4874 - accuracy: 0.7937 - val_loss: 0.4763 - val_accuracy: 0.7955\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.8058 - val_loss: 0.4670 - val_accuracy: 0.7955\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7935 - val_loss: 0.4591 - val_accuracy: 0.7955\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.8041 - val_loss: 0.4524 - val_accuracy: 0.7955\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8083 - val_loss: 0.4468 - val_accuracy: 0.7955\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.7928 - val_loss: 0.4419 - val_accuracy: 0.7955\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.4377 - val_accuracy: 0.7955\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4243 - accuracy: 0.7999 - val_loss: 0.4343 - val_accuracy: 0.7955\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.4312 - val_accuracy: 0.7955\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4152 - accuracy: 0.8014 - val_loss: 0.4285 - val_accuracy: 0.7955\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4324 - accuracy: 0.7916 - val_loss: 0.4263 - val_accuracy: 0.7955\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4080 - accuracy: 0.8026 - val_loss: 0.4240 - val_accuracy: 0.7955\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4027 - accuracy: 0.7964 - val_loss: 0.4218 - val_accuracy: 0.7955\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4063 - accuracy: 0.7980 - val_loss: 0.4201 - val_accuracy: 0.7955\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4147 - accuracy: 0.8000 - val_loss: 0.4183 - val_accuracy: 0.8061\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4145 - accuracy: 0.8101 - val_loss: 0.4164 - val_accuracy: 0.8065\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4159 - accuracy: 0.8032 - val_loss: 0.4147 - val_accuracy: 0.8065\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8134 - val_loss: 0.4128 - val_accuracy: 0.8213\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.8213 - val_loss: 0.4110 - val_accuracy: 0.8224\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4033 - accuracy: 0.8274 - val_loss: 0.4090 - val_accuracy: 0.8251\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3981 - accuracy: 0.8299 - val_loss: 0.4072 - val_accuracy: 0.8262\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3961 - accuracy: 0.8342 - val_loss: 0.4051 - val_accuracy: 0.8289\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3881 - accuracy: 0.8405 - val_loss: 0.4033 - val_accuracy: 0.8281\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8420 - val_loss: 0.4017 - val_accuracy: 0.8292\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3863 - accuracy: 0.8402 - val_loss: 0.3999 - val_accuracy: 0.8277\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3967 - accuracy: 0.8333 - val_loss: 0.3984 - val_accuracy: 0.8285\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8474 - val_loss: 0.3965 - val_accuracy: 0.8304\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3904 - accuracy: 0.8405 - val_loss: 0.3947 - val_accuracy: 0.8326\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3714 - accuracy: 0.8447 - val_loss: 0.3930 - val_accuracy: 0.8342\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8441 - val_loss: 0.3914 - val_accuracy: 0.8345\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8425 - val_loss: 0.3900 - val_accuracy: 0.8349\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3766 - accuracy: 0.8426 - val_loss: 0.3883 - val_accuracy: 0.8376\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8506 - val_loss: 0.3867 - val_accuracy: 0.8395\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3806 - accuracy: 0.8432 - val_loss: 0.3854 - val_accuracy: 0.8410\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8517 - val_loss: 0.3840 - val_accuracy: 0.8417\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3714 - accuracy: 0.8462 - val_loss: 0.3829 - val_accuracy: 0.8432\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8575 - val_loss: 0.3817 - val_accuracy: 0.8436\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3558 - accuracy: 0.8536 - val_loss: 0.3807 - val_accuracy: 0.8444\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8549 - val_loss: 0.3796 - val_accuracy: 0.8436\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3581 - accuracy: 0.8531 - val_loss: 0.3788 - val_accuracy: 0.8444\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3673 - accuracy: 0.8526 - val_loss: 0.3779 - val_accuracy: 0.8474\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3760 - accuracy: 0.8508 - val_loss: 0.3772 - val_accuracy: 0.8466\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3578 - accuracy: 0.8517 - val_loss: 0.3765 - val_accuracy: 0.8485\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8558 - val_loss: 0.3761 - val_accuracy: 0.8474\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3563 - accuracy: 0.8570 - val_loss: 0.3755 - val_accuracy: 0.8478\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.8643 - val_loss: 0.3749 - val_accuracy: 0.8466\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8586 - val_loss: 0.3745 - val_accuracy: 0.8459\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3580 - accuracy: 0.8560 - val_loss: 0.3740 - val_accuracy: 0.8463\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8564 - val_loss: 0.3736 - val_accuracy: 0.8459\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8625 - val_loss: 0.3732 - val_accuracy: 0.8474\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8590 - val_loss: 0.3726 - val_accuracy: 0.8463\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8594 - val_loss: 0.3722 - val_accuracy: 0.8463\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8631 - val_loss: 0.3718 - val_accuracy: 0.8463\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8632 - val_loss: 0.3716 - val_accuracy: 0.8482\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3590 - accuracy: 0.8587 - val_loss: 0.3712 - val_accuracy: 0.8466\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3538 - accuracy: 0.8639 - val_loss: 0.3709 - val_accuracy: 0.8470\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8640 - val_loss: 0.3707 - val_accuracy: 0.8478\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8620 - val_loss: 0.3705 - val_accuracy: 0.8482\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8609 - val_loss: 0.3702 - val_accuracy: 0.8482\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8624 - val_loss: 0.3698 - val_accuracy: 0.8485\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8651 - val_loss: 0.3697 - val_accuracy: 0.8512\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3556 - accuracy: 0.8561 - val_loss: 0.3696 - val_accuracy: 0.8508\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8622 - val_loss: 0.3692 - val_accuracy: 0.8489\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8612 - val_loss: 0.3688 - val_accuracy: 0.8504\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8538 - val_loss: 0.3688 - val_accuracy: 0.8519\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8594 - val_loss: 0.3683 - val_accuracy: 0.8508\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8604 - val_loss: 0.3682 - val_accuracy: 0.8516\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8672 - val_loss: 0.3678 - val_accuracy: 0.8519\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8643 - val_loss: 0.3677 - val_accuracy: 0.8519\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8637 - val_loss: 0.3679 - val_accuracy: 0.8508\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8536 - val_loss: 0.3677 - val_accuracy: 0.8516\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3574 - accuracy: 0.8534 - val_loss: 0.3673 - val_accuracy: 0.8508\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8656 - val_loss: 0.3671 - val_accuracy: 0.8531\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8656 - val_loss: 0.3670 - val_accuracy: 0.8523\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8705 - val_loss: 0.3667 - val_accuracy: 0.8527\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8566 - val_loss: 0.3664 - val_accuracy: 0.8516\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8624 - val_loss: 0.3661 - val_accuracy: 0.8516\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8690 - val_loss: 0.3659 - val_accuracy: 0.8516\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8640 - val_loss: 0.3657 - val_accuracy: 0.8508\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8580 - val_loss: 0.3656 - val_accuracy: 0.8523\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3381 - accuracy: 0.8655 - val_loss: 0.3651 - val_accuracy: 0.8512\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8589 - val_loss: 0.3649 - val_accuracy: 0.8516\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8684 - val_loss: 0.3646 - val_accuracy: 0.8527\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.8662 - val_loss: 0.3645 - val_accuracy: 0.8516\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8590 - val_loss: 0.3646 - val_accuracy: 0.8512\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3361 - accuracy: 0.8568 - val_loss: 0.3645 - val_accuracy: 0.8508\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8608 - val_loss: 0.3641 - val_accuracy: 0.8512\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8644 - val_loss: 0.3639 - val_accuracy: 0.8504\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8588 - val_loss: 0.3638 - val_accuracy: 0.8512\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8623 - val_loss: 0.3637 - val_accuracy: 0.8508\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.8614 - val_loss: 0.3635 - val_accuracy: 0.8501\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3365 - accuracy: 0.8617 - val_loss: 0.3633 - val_accuracy: 0.8497\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8655 - val_loss: 0.3632 - val_accuracy: 0.8504\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8665 - val_loss: 0.3630 - val_accuracy: 0.8512\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8648 - val_loss: 0.3628 - val_accuracy: 0.8508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tyRjHk9ugoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48030ae-6934-488c-bd88-556c6d39c826"
      },
      "source": [
        "ypred = classifier.predict(X_test)\n",
        "ypred = (ypred > 0.5)\n",
        "ypred"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       ...,\n",
              "       [False],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGk8Co9PxTfb"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS9hJaZ5xiIQ",
        "outputId": "196f4ae7-6ccf-4969-8e8f-2a2a35b34546"
      },
      "source": [
        "print(\"Confussion matrix:\", confusion_matrix(y_test,ypred))\n",
        "print(\"Accuracy score:\", accuracy_score(y_test,ypred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confussion matrix: [[1508   87]\n",
            " [ 199  206]]\n",
            "Accuracy score: 0.857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVxqlvrMyzoA",
        "outputId": "013e6800-fd89-4e9b-cb69-f575e1009420"
      },
      "source": [
        "#tried with optimiser adam\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(units=6,activation='relu',kernel_initializer='he_uniform',input_dim=13))\n",
        "#second layer\n",
        "classifier.add(Dense(units=6,activation='relu',kernel_initializer='he_uniform'))\n",
        "#output layer\n",
        "classifier.add(Dense(units=1,activation='sigmoid',kernel_initializer='glorot_uniform'))\n",
        "print(\"Classifier.summary\",classifier.summary())\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)\n",
        "ypred = classifier.predict(X_test)\n",
        "ypred = (ypred > 0.5)\n",
        "print(\"Confussion matrix:\", confusion_matrix(y_test,ypred))\n",
        "print(\"Accuracy score:\", accuracy_score(y_test,ypred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 6)                 84        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 133\n",
            "Trainable params: 133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Classifier.summary None\n",
            "Epoch 1/100\n",
            "536/536 [==============================] - 2s 2ms/step - loss: 0.5501 - accuracy: 0.7939 - val_loss: 0.5089 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7970 - val_loss: 0.4852 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7949 - val_loss: 0.4688 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.8051 - val_loss: 0.4564 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.4481 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4308 - accuracy: 0.7966 - val_loss: 0.4421 - val_accuracy: 0.7955\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.7891 - val_loss: 0.4378 - val_accuracy: 0.7955\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4142 - accuracy: 0.8039 - val_loss: 0.4331 - val_accuracy: 0.8001\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4147 - accuracy: 0.8102 - val_loss: 0.4276 - val_accuracy: 0.8088\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4064 - accuracy: 0.8169 - val_loss: 0.4208 - val_accuracy: 0.8160\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8253 - val_loss: 0.4148 - val_accuracy: 0.8179\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3937 - accuracy: 0.8299 - val_loss: 0.4073 - val_accuracy: 0.8213\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8345 - val_loss: 0.4015 - val_accuracy: 0.8247\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3873 - accuracy: 0.8355 - val_loss: 0.3979 - val_accuracy: 0.8270\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8402 - val_loss: 0.3922 - val_accuracy: 0.8289\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3761 - accuracy: 0.8363 - val_loss: 0.3890 - val_accuracy: 0.8319\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3715 - accuracy: 0.8479 - val_loss: 0.3888 - val_accuracy: 0.8349\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8496 - val_loss: 0.3838 - val_accuracy: 0.8334\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8427 - val_loss: 0.3827 - val_accuracy: 0.8417\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3720 - accuracy: 0.8417 - val_loss: 0.3798 - val_accuracy: 0.8455\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8528 - val_loss: 0.3775 - val_accuracy: 0.8391\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8555 - val_loss: 0.3765 - val_accuracy: 0.8440\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8576 - val_loss: 0.3742 - val_accuracy: 0.8444\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.8600 - val_loss: 0.3723 - val_accuracy: 0.8451\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8626 - val_loss: 0.3735 - val_accuracy: 0.8474\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3542 - accuracy: 0.8525 - val_loss: 0.3696 - val_accuracy: 0.8512\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8670 - val_loss: 0.3681 - val_accuracy: 0.8501\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8686 - val_loss: 0.3671 - val_accuracy: 0.8535\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8620 - val_loss: 0.3645 - val_accuracy: 0.8523\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8647 - val_loss: 0.3637 - val_accuracy: 0.8565\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8591 - val_loss: 0.3639 - val_accuracy: 0.8523\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8581 - val_loss: 0.3627 - val_accuracy: 0.8554\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8533 - val_loss: 0.3619 - val_accuracy: 0.8565\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8694 - val_loss: 0.3612 - val_accuracy: 0.8573\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8648 - val_loss: 0.3611 - val_accuracy: 0.8561\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8604 - val_loss: 0.3619 - val_accuracy: 0.8550\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.8737 - val_loss: 0.3587 - val_accuracy: 0.8569\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8675 - val_loss: 0.3604 - val_accuracy: 0.8535\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.8695 - val_loss: 0.3588 - val_accuracy: 0.8554\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.8723 - val_loss: 0.3585 - val_accuracy: 0.8546\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8561 - val_loss: 0.3591 - val_accuracy: 0.8554\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8584 - val_loss: 0.3593 - val_accuracy: 0.8542\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8661 - val_loss: 0.3598 - val_accuracy: 0.8546\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8612 - val_loss: 0.3598 - val_accuracy: 0.8531\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8618 - val_loss: 0.3594 - val_accuracy: 0.8550\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8613 - val_loss: 0.3583 - val_accuracy: 0.8557\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8651 - val_loss: 0.3566 - val_accuracy: 0.8546\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8664 - val_loss: 0.3560 - val_accuracy: 0.8580\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8703 - val_loss: 0.3581 - val_accuracy: 0.8542\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8678 - val_loss: 0.3566 - val_accuracy: 0.8557\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3188 - accuracy: 0.8671 - val_loss: 0.3553 - val_accuracy: 0.8569\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8635 - val_loss: 0.3564 - val_accuracy: 0.8523\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8663 - val_loss: 0.3556 - val_accuracy: 0.8584\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8651 - val_loss: 0.3561 - val_accuracy: 0.8565\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8601 - val_loss: 0.3587 - val_accuracy: 0.8523\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8676 - val_loss: 0.3575 - val_accuracy: 0.8538\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.8672 - val_loss: 0.3583 - val_accuracy: 0.8531\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8672 - val_loss: 0.3573 - val_accuracy: 0.8546\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8781 - val_loss: 0.3566 - val_accuracy: 0.8565\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8645 - val_loss: 0.3583 - val_accuracy: 0.8565\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8657 - val_loss: 0.3563 - val_accuracy: 0.8607\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8624 - val_loss: 0.3560 - val_accuracy: 0.8595\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8606 - val_loss: 0.3616 - val_accuracy: 0.8523\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8641 - val_loss: 0.3557 - val_accuracy: 0.8565\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8605 - val_loss: 0.3582 - val_accuracy: 0.8569\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8669 - val_loss: 0.3552 - val_accuracy: 0.8603\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8641 - val_loss: 0.3558 - val_accuracy: 0.8546\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8667 - val_loss: 0.3541 - val_accuracy: 0.8603\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3146 - accuracy: 0.8725 - val_loss: 0.3560 - val_accuracy: 0.8603\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.8671 - val_loss: 0.3579 - val_accuracy: 0.8610\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8698 - val_loss: 0.3545 - val_accuracy: 0.8561\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8624 - val_loss: 0.3561 - val_accuracy: 0.8576\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8658 - val_loss: 0.3545 - val_accuracy: 0.8588\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8604 - val_loss: 0.3558 - val_accuracy: 0.8584\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8674 - val_loss: 0.3555 - val_accuracy: 0.8595\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8618 - val_loss: 0.3558 - val_accuracy: 0.8550\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3152 - accuracy: 0.8642 - val_loss: 0.3556 - val_accuracy: 0.8599\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8626 - val_loss: 0.3540 - val_accuracy: 0.8610\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3125 - accuracy: 0.8712 - val_loss: 0.3550 - val_accuracy: 0.8584\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.8646 - val_loss: 0.3532 - val_accuracy: 0.8599\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8610 - val_loss: 0.3538 - val_accuracy: 0.8607\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8653 - val_loss: 0.3533 - val_accuracy: 0.8614\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8689 - val_loss: 0.3550 - val_accuracy: 0.8607\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.8739 - val_loss: 0.3542 - val_accuracy: 0.8614\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8645 - val_loss: 0.3548 - val_accuracy: 0.8588\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8628 - val_loss: 0.3538 - val_accuracy: 0.8576\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8628 - val_loss: 0.3554 - val_accuracy: 0.8599\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8617 - val_loss: 0.3529 - val_accuracy: 0.8565\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8655 - val_loss: 0.3556 - val_accuracy: 0.8626\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8591 - val_loss: 0.3547 - val_accuracy: 0.8588\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8654 - val_loss: 0.3541 - val_accuracy: 0.8618\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.8652 - val_loss: 0.3541 - val_accuracy: 0.8599\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8490 - val_loss: 0.3542 - val_accuracy: 0.8588\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8637 - val_loss: 0.3526 - val_accuracy: 0.8622\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.8681 - val_loss: 0.3544 - val_accuracy: 0.8588\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.8747 - val_loss: 0.3536 - val_accuracy: 0.8610\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.8683 - val_loss: 0.3532 - val_accuracy: 0.8573\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3352 - accuracy: 0.8627 - val_loss: 0.3548 - val_accuracy: 0.8599\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.8686 - val_loss: 0.3536 - val_accuracy: 0.8614\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.8678 - val_loss: 0.3535 - val_accuracy: 0.8588\n",
            "Confussion matrix: [[1498   97]\n",
            " [ 182  223]]\n",
            "Accuracy score: 0.8605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYT2fJvwyQB1",
        "outputId": "20f230aa-d5f3-4c97-f1a4-57eeefdcc68d"
      },
      "source": [
        "#tried with optimiser adam increase in no of neuron and added a new hidden layer\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(units=10,activation='relu',kernel_initializer='he_uniform',input_dim=13))\n",
        "#second layer\n",
        "classifier.add(Dense(units=20,activation='relu',kernel_initializer='he_uniform'))\n",
        "#third layer\n",
        "classifier.add(Dense(units=30,activation='relu',kernel_initializer='he_uniform'))\n",
        "#output layer\n",
        "classifier.add(Dense(units=1,activation='sigmoid',kernel_initializer='glorot_uniform'))\n",
        "print(\"Classifier.summary\",classifier.summary())\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)\n",
        "ypred = classifier.predict(X_test)\n",
        "ypred = (ypred > 0.5)\n",
        "print(\"Confussion matrix:\", confusion_matrix(y_test,ypred))\n",
        "print(\"Accuracy score:\", accuracy_score(y_test,ypred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_30 (Dense)             (None, 10)                120       \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 30)                630       \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 1,001\n",
            "Trainable params: 1,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Classifier.summary None\n",
            "Epoch 1/100\n",
            "536/536 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7616 - val_loss: 0.4573 - val_accuracy: 0.8005\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.8123 - val_loss: 0.4404 - val_accuracy: 0.8073\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8048 - val_loss: 0.4291 - val_accuracy: 0.8201\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3924 - accuracy: 0.8277 - val_loss: 0.4121 - val_accuracy: 0.8289\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3793 - accuracy: 0.8406 - val_loss: 0.4078 - val_accuracy: 0.8232\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3797 - accuracy: 0.8398 - val_loss: 0.3917 - val_accuracy: 0.8315\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8535 - val_loss: 0.3859 - val_accuracy: 0.8376\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8484 - val_loss: 0.3860 - val_accuracy: 0.8429\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8455 - val_loss: 0.3737 - val_accuracy: 0.8421\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8594 - val_loss: 0.3730 - val_accuracy: 0.8451\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8557 - val_loss: 0.3732 - val_accuracy: 0.8425\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8567 - val_loss: 0.3712 - val_accuracy: 0.8444\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8532 - val_loss: 0.3747 - val_accuracy: 0.8421\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8582 - val_loss: 0.3747 - val_accuracy: 0.8421\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8664 - val_loss: 0.3699 - val_accuracy: 0.8451\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8584 - val_loss: 0.3670 - val_accuracy: 0.8497\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8642 - val_loss: 0.3717 - val_accuracy: 0.8489\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.8596 - val_loss: 0.3659 - val_accuracy: 0.8485\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3216 - accuracy: 0.8610 - val_loss: 0.3695 - val_accuracy: 0.8493\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8605 - val_loss: 0.3738 - val_accuracy: 0.8413\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3195 - accuracy: 0.8651 - val_loss: 0.3812 - val_accuracy: 0.8413\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3081 - accuracy: 0.8762 - val_loss: 0.3680 - val_accuracy: 0.8466\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8652 - val_loss: 0.3775 - val_accuracy: 0.8478\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8734 - val_loss: 0.3701 - val_accuracy: 0.8474\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8642 - val_loss: 0.3763 - val_accuracy: 0.8459\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8609 - val_loss: 0.3713 - val_accuracy: 0.8482\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8544 - val_loss: 0.3753 - val_accuracy: 0.8448\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8678 - val_loss: 0.3708 - val_accuracy: 0.8485\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3187 - accuracy: 0.8622 - val_loss: 0.3694 - val_accuracy: 0.8474\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8675 - val_loss: 0.3684 - val_accuracy: 0.8497\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8763 - val_loss: 0.3727 - val_accuracy: 0.8478\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.8702 - val_loss: 0.3735 - val_accuracy: 0.8455\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3115 - accuracy: 0.8651 - val_loss: 0.3701 - val_accuracy: 0.8451\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.8745 - val_loss: 0.3680 - val_accuracy: 0.8455\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8611 - val_loss: 0.3719 - val_accuracy: 0.8504\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3013 - accuracy: 0.8731 - val_loss: 0.3755 - val_accuracy: 0.8489\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3105 - accuracy: 0.8769 - val_loss: 0.3741 - val_accuracy: 0.8493\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3012 - accuracy: 0.8747 - val_loss: 0.3716 - val_accuracy: 0.8466\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8617 - val_loss: 0.3704 - val_accuracy: 0.8519\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8630 - val_loss: 0.3740 - val_accuracy: 0.8512\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8665 - val_loss: 0.3715 - val_accuracy: 0.8531\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3041 - accuracy: 0.8689 - val_loss: 0.3708 - val_accuracy: 0.8501\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8670 - val_loss: 0.3764 - val_accuracy: 0.8516\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2904 - accuracy: 0.8757 - val_loss: 0.3727 - val_accuracy: 0.8519\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.8711 - val_loss: 0.3760 - val_accuracy: 0.8493\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3010 - accuracy: 0.8728 - val_loss: 0.3748 - val_accuracy: 0.8497\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8669 - val_loss: 0.3725 - val_accuracy: 0.8519\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8696 - val_loss: 0.3752 - val_accuracy: 0.8497\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3121 - accuracy: 0.8663 - val_loss: 0.3732 - val_accuracy: 0.8512\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.8651 - val_loss: 0.3811 - val_accuracy: 0.8493\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2999 - accuracy: 0.8750 - val_loss: 0.3775 - val_accuracy: 0.8516\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.8680 - val_loss: 0.3838 - val_accuracy: 0.8550\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.8696 - val_loss: 0.3839 - val_accuracy: 0.8451\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8694 - val_loss: 0.3810 - val_accuracy: 0.8527\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2936 - accuracy: 0.8754 - val_loss: 0.3778 - val_accuracy: 0.8519\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2904 - accuracy: 0.8786 - val_loss: 0.3801 - val_accuracy: 0.8444\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.8803 - val_loss: 0.3782 - val_accuracy: 0.8531\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2957 - accuracy: 0.8737 - val_loss: 0.3832 - val_accuracy: 0.8470\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2991 - accuracy: 0.8654 - val_loss: 0.3818 - val_accuracy: 0.8523\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8802 - val_loss: 0.3809 - val_accuracy: 0.8501\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.8819 - val_loss: 0.3851 - val_accuracy: 0.8531\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2965 - accuracy: 0.8699 - val_loss: 0.3870 - val_accuracy: 0.8432\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8795 - val_loss: 0.3895 - val_accuracy: 0.8406\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8664 - val_loss: 0.3802 - val_accuracy: 0.8482\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8693 - val_loss: 0.3807 - val_accuracy: 0.8531\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2946 - accuracy: 0.8702 - val_loss: 0.3835 - val_accuracy: 0.8474\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3074 - accuracy: 0.8648 - val_loss: 0.3835 - val_accuracy: 0.8485\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3016 - accuracy: 0.8694 - val_loss: 0.3840 - val_accuracy: 0.8538\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3019 - accuracy: 0.8679 - val_loss: 0.3836 - val_accuracy: 0.8485\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8852 - val_loss: 0.3852 - val_accuracy: 0.8531\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2916 - accuracy: 0.8772 - val_loss: 0.3835 - val_accuracy: 0.8493\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.8766 - val_loss: 0.3899 - val_accuracy: 0.8546\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2950 - accuracy: 0.8787 - val_loss: 0.3850 - val_accuracy: 0.8497\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2866 - accuracy: 0.8775 - val_loss: 0.3886 - val_accuracy: 0.8478\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2801 - accuracy: 0.8824 - val_loss: 0.3821 - val_accuracy: 0.8546\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2917 - accuracy: 0.8686 - val_loss: 0.3834 - val_accuracy: 0.8489\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2968 - accuracy: 0.8749 - val_loss: 0.3923 - val_accuracy: 0.8512\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.8811 - val_loss: 0.3892 - val_accuracy: 0.8504\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.8698 - val_loss: 0.3894 - val_accuracy: 0.8478\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2790 - accuracy: 0.8790 - val_loss: 0.3911 - val_accuracy: 0.8463\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2890 - accuracy: 0.8707 - val_loss: 0.3895 - val_accuracy: 0.8508\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2898 - accuracy: 0.8774 - val_loss: 0.3924 - val_accuracy: 0.8504\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8707 - val_loss: 0.3928 - val_accuracy: 0.8478\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2775 - accuracy: 0.8825 - val_loss: 0.3863 - val_accuracy: 0.8493\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2690 - accuracy: 0.8866 - val_loss: 0.3917 - val_accuracy: 0.8550\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8806 - val_loss: 0.3881 - val_accuracy: 0.8535\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2841 - accuracy: 0.8790 - val_loss: 0.3922 - val_accuracy: 0.8531\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8737 - val_loss: 0.3898 - val_accuracy: 0.8504\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2791 - accuracy: 0.8802 - val_loss: 0.3923 - val_accuracy: 0.8410\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2862 - accuracy: 0.8789 - val_loss: 0.3970 - val_accuracy: 0.8508\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2813 - accuracy: 0.8813 - val_loss: 0.3902 - val_accuracy: 0.8459\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8720 - val_loss: 0.3952 - val_accuracy: 0.8482\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.8799 - val_loss: 0.3932 - val_accuracy: 0.8463\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8770 - val_loss: 0.3976 - val_accuracy: 0.8463\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.8762 - val_loss: 0.3923 - val_accuracy: 0.8470\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8781 - val_loss: 0.3932 - val_accuracy: 0.8421\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.8838 - val_loss: 0.3976 - val_accuracy: 0.8485\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2955 - accuracy: 0.8685 - val_loss: 0.3985 - val_accuracy: 0.8429\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.8774 - val_loss: 0.3991 - val_accuracy: 0.8459\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.8836 - val_loss: 0.3991 - val_accuracy: 0.8432\n",
            "Confussion matrix: [[1457  138]\n",
            " [ 174  231]]\n",
            "Accuracy score: 0.844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcHSWGrK0Hl-",
        "outputId": "189160c8-d545-4899-a7c0-9dd7b02c81e1"
      },
      "source": [
        "# lets try dropout\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(units=10,activation='relu',kernel_initializer='he_uniform',input_dim=13))\n",
        "classifier.add(Dropout(0.2))\n",
        "#second layer\n",
        "classifier.add(Dense(units=20,activation='relu',kernel_initializer='he_uniform'))\n",
        "classifier.add(Dropout(0.3))\n",
        "#third layer\n",
        "classifier.add(Dense(units=30,activation='relu',kernel_initializer='he_uniform'))\n",
        "classifier.add(Dropout(0.4))\n",
        "#output layer\n",
        "classifier.add(Dense(units=1,activation='sigmoid',kernel_initializer='glorot_uniform'))\n",
        "print(\"Classifier.summary\",classifier.summary())\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)\n",
        "ypred = classifier.predict(X_test)\n",
        "ypred = (ypred > 0.5)\n",
        "print(\"Confussion matrix:\", confusion_matrix(y_test,ypred))\n",
        "print(\"Accuracy score:\", accuracy_score(y_test,ypred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_34 (Dense)             (None, 10)                120       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 30)                630       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 1,001\n",
            "Trainable params: 1,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Classifier.summary None\n",
            "Epoch 1/100\n",
            "536/536 [==============================] - 2s 2ms/step - loss: 0.7930 - accuracy: 0.6412 - val_loss: 0.4895 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7826 - val_loss: 0.4737 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7875 - val_loss: 0.4645 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4926 - accuracy: 0.7953 - val_loss: 0.4564 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7994 - val_loss: 0.4495 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7960 - val_loss: 0.4421 - val_accuracy: 0.7955\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4516 - accuracy: 0.8045 - val_loss: 0.4316 - val_accuracy: 0.7955\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.7991 - val_loss: 0.4218 - val_accuracy: 0.8118\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.8043 - val_loss: 0.4156 - val_accuracy: 0.8095\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8055 - val_loss: 0.4096 - val_accuracy: 0.8137\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8070 - val_loss: 0.4061 - val_accuracy: 0.8220\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8207 - val_loss: 0.3997 - val_accuracy: 0.8311\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8312 - val_loss: 0.3942 - val_accuracy: 0.8319\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4251 - accuracy: 0.8153 - val_loss: 0.3855 - val_accuracy: 0.8364\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3886 - accuracy: 0.8372 - val_loss: 0.3822 - val_accuracy: 0.8342\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3930 - accuracy: 0.8302 - val_loss: 0.3790 - val_accuracy: 0.8353\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3927 - accuracy: 0.8304 - val_loss: 0.3796 - val_accuracy: 0.8357\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3904 - accuracy: 0.8367 - val_loss: 0.3750 - val_accuracy: 0.8383\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3921 - accuracy: 0.8389 - val_loss: 0.3779 - val_accuracy: 0.8387\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3788 - accuracy: 0.8433 - val_loss: 0.3753 - val_accuracy: 0.8387\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3809 - accuracy: 0.8447 - val_loss: 0.3723 - val_accuracy: 0.8417\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3838 - accuracy: 0.8447 - val_loss: 0.3738 - val_accuracy: 0.8410\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3764 - accuracy: 0.8408 - val_loss: 0.3712 - val_accuracy: 0.8406\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8490 - val_loss: 0.3693 - val_accuracy: 0.8417\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3782 - accuracy: 0.8417 - val_loss: 0.3683 - val_accuracy: 0.8406\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8455 - val_loss: 0.3720 - val_accuracy: 0.8402\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3746 - accuracy: 0.8395 - val_loss: 0.3704 - val_accuracy: 0.8413\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.8361 - val_loss: 0.3709 - val_accuracy: 0.8425\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8449 - val_loss: 0.3639 - val_accuracy: 0.8455\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3850 - accuracy: 0.8438 - val_loss: 0.3706 - val_accuracy: 0.8383\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3799 - accuracy: 0.8410 - val_loss: 0.3738 - val_accuracy: 0.8406\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3796 - accuracy: 0.8443 - val_loss: 0.3674 - val_accuracy: 0.8463\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8472 - val_loss: 0.3695 - val_accuracy: 0.8417\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3750 - accuracy: 0.8477 - val_loss: 0.3700 - val_accuracy: 0.8451\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8436 - val_loss: 0.3647 - val_accuracy: 0.8463\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3704 - accuracy: 0.8453 - val_loss: 0.3693 - val_accuracy: 0.8432\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8510 - val_loss: 0.3646 - val_accuracy: 0.8485\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8447 - val_loss: 0.3675 - val_accuracy: 0.8421\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3692 - accuracy: 0.8495 - val_loss: 0.3752 - val_accuracy: 0.8421\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3510 - accuracy: 0.8555 - val_loss: 0.3648 - val_accuracy: 0.8501\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3493 - accuracy: 0.8566 - val_loss: 0.3674 - val_accuracy: 0.8429\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3719 - accuracy: 0.8462 - val_loss: 0.3620 - val_accuracy: 0.8474\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8497 - val_loss: 0.3667 - val_accuracy: 0.8485\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3686 - accuracy: 0.8491 - val_loss: 0.3658 - val_accuracy: 0.8466\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3710 - accuracy: 0.8457 - val_loss: 0.3659 - val_accuracy: 0.8463\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3757 - accuracy: 0.8448 - val_loss: 0.3629 - val_accuracy: 0.8516\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3665 - accuracy: 0.8467 - val_loss: 0.3637 - val_accuracy: 0.8444\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8542 - val_loss: 0.3659 - val_accuracy: 0.8444\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8405 - val_loss: 0.3667 - val_accuracy: 0.8448\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3685 - accuracy: 0.8476 - val_loss: 0.3649 - val_accuracy: 0.8470\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8620 - val_loss: 0.3641 - val_accuracy: 0.8470\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3711 - accuracy: 0.8482 - val_loss: 0.3599 - val_accuracy: 0.8512\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8605 - val_loss: 0.3645 - val_accuracy: 0.8489\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3857 - accuracy: 0.8441 - val_loss: 0.3630 - val_accuracy: 0.8459\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8457 - val_loss: 0.3614 - val_accuracy: 0.8478\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3799 - accuracy: 0.8444 - val_loss: 0.3612 - val_accuracy: 0.8482\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8487 - val_loss: 0.3636 - val_accuracy: 0.8482\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3567 - accuracy: 0.8498 - val_loss: 0.3638 - val_accuracy: 0.8482\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3714 - accuracy: 0.8437 - val_loss: 0.3646 - val_accuracy: 0.8444\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3549 - accuracy: 0.8518 - val_loss: 0.3618 - val_accuracy: 0.8459\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8530 - val_loss: 0.3615 - val_accuracy: 0.8497\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3662 - accuracy: 0.8546 - val_loss: 0.3671 - val_accuracy: 0.8451\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8366 - val_loss: 0.3631 - val_accuracy: 0.8489\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3820 - accuracy: 0.8462 - val_loss: 0.3607 - val_accuracy: 0.8489\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8594 - val_loss: 0.3607 - val_accuracy: 0.8485\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8514 - val_loss: 0.3645 - val_accuracy: 0.8493\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3563 - accuracy: 0.8573 - val_loss: 0.3602 - val_accuracy: 0.8527\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3519 - accuracy: 0.8510 - val_loss: 0.3634 - val_accuracy: 0.8497\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.8491 - val_loss: 0.3616 - val_accuracy: 0.8516\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8605 - val_loss: 0.3631 - val_accuracy: 0.8455\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8531 - val_loss: 0.3613 - val_accuracy: 0.8504\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8554 - val_loss: 0.3621 - val_accuracy: 0.8497\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8587 - val_loss: 0.3620 - val_accuracy: 0.8501\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3663 - accuracy: 0.8444 - val_loss: 0.3639 - val_accuracy: 0.8497\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8482 - val_loss: 0.3610 - val_accuracy: 0.8489\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8463 - val_loss: 0.3645 - val_accuracy: 0.8474\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3535 - accuracy: 0.8496 - val_loss: 0.3604 - val_accuracy: 0.8489\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3791 - accuracy: 0.8397 - val_loss: 0.3647 - val_accuracy: 0.8466\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3571 - accuracy: 0.8552 - val_loss: 0.3661 - val_accuracy: 0.8466\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8613 - val_loss: 0.3673 - val_accuracy: 0.8444\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3732 - accuracy: 0.8462 - val_loss: 0.3630 - val_accuracy: 0.8470\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8511 - val_loss: 0.3633 - val_accuracy: 0.8489\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8453 - val_loss: 0.3618 - val_accuracy: 0.8489\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8577 - val_loss: 0.3618 - val_accuracy: 0.8489\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8591 - val_loss: 0.3630 - val_accuracy: 0.8482\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8474 - val_loss: 0.3614 - val_accuracy: 0.8478\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8527 - val_loss: 0.3613 - val_accuracy: 0.8466\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.8526 - val_loss: 0.3612 - val_accuracy: 0.8504\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8622 - val_loss: 0.3616 - val_accuracy: 0.8474\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3537 - accuracy: 0.8537 - val_loss: 0.3615 - val_accuracy: 0.8482\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3604 - accuracy: 0.8503 - val_loss: 0.3629 - val_accuracy: 0.8470\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8575 - val_loss: 0.3608 - val_accuracy: 0.8474\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8404 - val_loss: 0.3621 - val_accuracy: 0.8474\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8480 - val_loss: 0.3595 - val_accuracy: 0.8470\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8606 - val_loss: 0.3624 - val_accuracy: 0.8478\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3549 - accuracy: 0.8551 - val_loss: 0.3628 - val_accuracy: 0.8474\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8640 - val_loss: 0.3603 - val_accuracy: 0.8482\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8425 - val_loss: 0.3606 - val_accuracy: 0.8489\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8506 - val_loss: 0.3589 - val_accuracy: 0.8478\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8524 - val_loss: 0.3625 - val_accuracy: 0.8485\n",
            "Confussion matrix: [[1572   23]\n",
            " [ 241  164]]\n",
            "Accuracy score: 0.868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Y9mMN_1kKh",
        "outputId": "cbe3654d-6198-492c-efc0-5a1eef88b8f2"
      },
      "source": [
        "print(model_history.history.keys())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fU7NYk4v2X56",
        "outputId": "64b25dd5-13f2-430c-93d9-a96eafa9631a"
      },
      "source": [
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('Loss history')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'])\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3zV5dn48c91sndCEmaABARkyYo4cQ8URVv6ULe2Vuuv+mhb9VFba1vtsO1Tq320dVWrddWqtSgoTnCihCFTJOwwQ0LInuf6/XF/Qw4xE3JyMq7363Ve5Ht/x7m+OXqu3ON736KqGGOMMW3lC3UAxhhjuhdLHMYYY9rFEocxxph2scRhjDGmXSxxGGOMaRdLHMYYY9rFEocxnURE/i4iv2phf6mIDOvMmIw5FJY4TK8jIptF5IxQx9GYqsar6saWjhGRU0Qkr7NiMqYpljiM6UVEJDzUMZjuzxKHMR4RiRKR+0Vkh/e6X0SivH1pIvK6iBSJSKGIfCgiPm/fbSKyXURKRGSdiJzewtukiMhc79jPRGR4wPuriBzh/XyuiKzxjtsuIreISBzwBjDQa9YqFZGBrcR9iojkeTHuAp4UkVUicn7A+0aIyF4RmdTxv1XTE1niMKbBT4FjgYnABGAqcKe372YgD0gH+gE/AVRERgE3AEeragJwNrC5hfe4CPglkALkAr9u5ri/Ad/3rjkOeE9Vy4BzgB1es1a8qu5oJW6A/kAfYChwLfA0cFnA/nOBnaq6rIW4jTnAEocxDS4F7lbVPaqaj/uCv9zbVwMMAIaqao2qfqhuorc6IAoYIyIRqrpZVTe08B7/VtXPVbUWeBb3Zd+UGu+aiaq6T1WXHmLcAH7g56papaoVwDPAuSKS6O2/HPhHC9c35iCWOIxpMBDYErC9xSsD+AOuhvCWiGwUkdsBVDUX+CHwC2CPiLwgIgNp3q6An8uB+GaOm4WrCWwRkYUictwhxg2Qr6qV9RteLeVjYJaIJONqMc+2cH1jDmKJw5gGO3DNOfWGeGWoaomq3qyqw4CZwI/r+zJU9TlVPdE7V4HfHW4gqrpYVS8A+gKvAi/W72pP3C2c8xSuueq/gE9Vdfvhxmx6D0scpreKEJHogFc48Dxwp4iki0gacBeuWQcROU9EjhARAfbjmqj8IjJKRE7zOqMrgQpc09AhE5FIEblURJJUtQYoDrjmbiBVRJICTmk27ha8CkwGbsL1eRjTZpY4TG81D/clX//6BfArIAdYAawElnplACOAd4BS4FPgL6r6Pq5/415gL64Zqi9wRwfEdzmwWUSKgetw/Rio6pe4RLHRG+E1sJW4m+T1dbwMZAGvdEC8phcRW8jJmN5JRO4CRqrqZa0ebEwAexjImF5IRPoAV3Pw6Ctj2sSaqozpZUTkGmAb8IaqfhDqeEz3Y01Vxhhj2sVqHMYYY9qlV/RxpKWlaWZmZqjDMMaYbmXJkiV7VTW9cXmvSByZmZnk5OSEOgxjjOlWRGRLU+XWVGWMMaZdLHEYY4xpF0scxhhj2qVX9HEYY0x71dTUkJeXR2VlZesHd3PR0dFkZGQQERHRpuMtcRhjTBPy8vJISEggMzMTN7dlz6SqFBQUkJeXR1ZWVpvOsaYqY4xpQmVlJampqT06aQCICKmpqe2qWVniMMaYZvT0pFGvvfcZ1MQhItNFZJ2I5NavmNZo/1Uiki8iy73X97zyiSLyqYisFpEVIvLtgHP+LiKbAs5pbunNw/bvZXk8s6jJYczGGNNrBS1xiEgY8BBuWcoxwMUiMqaJQ/+pqhO91+NeWTlwhaqOBaYD93tLXNa7NeCc5cG6h7krdvHcZ1uDdXljjGlWUVERf/nLX9p93rnnnktRUVEQImoQzBrHVCBXVTeqajXwAnBBW05U1a9Udb338w5gD/C1x96DLSkmgv0VNZ39tsYY02ziqK2tbfG8efPmkZyc3OIxhyuYiWMQburmenleWWOzvOaol0RkcOOdIjIViAQ2BBT/2jvnT96SnV8jIteKSI6I5OTn5x/SDSTHRlBUXn1I5xpjzOG4/fbb2bBhAxMnTuToo49m2rRpzJw5kzFjXMPNhRdeyJQpUxg7diyPPvrogfMyMzPZu3cvmzdvZvTo0VxzzTWMHTuWs846i4qKig6JLdTDcV8DnlfVKhH5PvAUcFr9ThEZAPwDuFJV69dcvgO3RGck8ChwG3B34wur6qPefrKzsw9p7vjkmAjKquuorvUTGW7jCIzprX752mrW7Cju0GuOGZjIz88f2+z+e++9l1WrVrF8+XIWLFjAjBkzWLVq1YEhs0888QR9+vShoqKCo48+mlmzZpGamnrQNdavX8/zzz/PY489xuzZs3n55Ze57LLDX/AxmN+G24HAGkSGV3aAqhaoapW3+TgwpX6fiCQCc4GfquqigHN2qlMFPIlrEguK5Fj3MIw1VxljQm3q1KkHPWfx5z//mQkTJnDssceybds21q9f/7VzsrKymDjRjR+aMmUKmzdv7pBYglnjWAyMEJEsXMK4CLgk8AARGaCqO73NmcBarzwS+DfwtKq+1NQ54saPXQisCtYNJMVGArC/opr0hCZbxIwxvUBLNYPOEhcXd+DnBQsW8M477/Dpp58SGxvLKaec0uRzGFFRDd9bYWFhXb+pSlVrReQGYD4QBjyhqqtF5G4gR1XnADeKyEygFigErvJOnw2cBKSKSH3ZVd4IqmdFJB0QYDlwXbDuITnG1TiKyq3GYYzpXAkJCZSUlDS5b//+/aSkpBAbG8uXX37JokWLmjwuWILax6Gq84B5jcruCvj5DlyfRePzngGeaeaapzVVHgz1TVWWOIwxnS01NZUTTjiBcePGERMTQ79+/Q7smz59Og8//DCjR49m1KhRHHvssZ0aW6g7x7u05BjXVFVkfRzGmBB47rnnmiyPiorijTfeaHJffT9GWloaq1Y1tOTfcsstHRaXDRVqQdKBGocNyTXGmHqWOFqQEBWOT6DYahzGGHOAJY4W+HxCUkyENVUZY0wASxytSIqJsM5xY4wJYImjFUmxkVbjMMaYAJY4WpEcE8F+6xw3xpgDLHG0IjnW+jiMMZ3vUKdVB7j//vspLy/v4IgaWOJoSV4Ok2uWWx+HMabTdeXEYQ8AtmTh7zhn12Z+UfkL6vxKmK93LCNpjAm9wGnVzzzzTPr27cuLL75IVVUV3/jGN/jlL39JWVkZs2fPJi8vj7q6On72s5+xe/duduzYwamnnkpaWhrvv/9+h8dmiaMlKZkkb/wEVaWksoZkb9JDY0wv88btsGtlx16z/3g4595mdwdOq/7WW2/x0ksv8fnnn6OqzJw5kw8++ID8/HwGDhzI3LlzATeHVVJSEvfddx/vv/8+aWlpHRuzx5qqWpKSRWRdKcmUWnOVMSZk3nrrLd566y0mTZrE5MmT+fLLL1m/fj3jx4/n7bff5rbbbuPDDz8kKSmpU+KxGkdLUjIBGCq7bU0OY3qzFmoGnUFVueOOO/j+97//tX1Lly5l3rx53HnnnZx++uncddddTVyhY1mNoyVe4hgie2xklTGmUwVOq3722WfzxBNPUFpaCsD27dvZs2cPO3bsIDY2lssuu4xbb72VpUuXfu3cYLAaR0tShgIwWPbYRIfGmE4VOK36OeecwyWXXMJxxx0HQHx8PM888wy5ubnceuut+Hw+IiIi+Otf/wrAtddey/Tp0xk4cGBQOsdF9ZCW427bxUWmAw/gFnJ6XFXvbbT/KuAPNCwp+6CqPu7tuxK40yv/lao+5ZVPAf4OxODW+rhJW7mJ7OxszcnJOaR78P9hBP/aP4aqGQ9wxXGZh3QNY0z3s3btWkaPHh3qMDpNU/crIktUNbvxsUFrqhKRMOAh4BxgDHCxiIxp4tB/qupE71WfNPoAPweOwa0p/nMRSfGO/ytwDTDCe00P1j0AkJLpmqqsc9wYY4Dg9nFMBXJVdaOqVgMvABe08dyzgbdVtVBV9wFvA9NFZACQqKqLvFrG07h1x4PG1yeLoT5LHMYYUy+YiWMQsC1gO88ra2yWiKwQkZdEZHAr5w7yfm7tmojItSKSIyI5+fn5h3oPkJJFfymgpLzs0K9hjOmWgtmU35W09z5DParqNSBTVY/C1Sqe6qgLq+qjqpqtqtnp6emHfqGUTHwoEcV5rR9rjOkxoqOjKSgo6PHJQ1UpKCggOjq6zecEc1TVdmBwwHYGDZ3gAKhqQcDm48DvA849pdG5C7zyjJau2eG8IbkxZdtaPs4Y06NkZGSQl5fHYbVYdBPR0dFkZGS0fqAnmIljMTBCRLJwX+4XAZcEHiAiA1R1p7c5E1jr/Twf+E1Ah/hZwB2qWigixSJyLPAZcAXwf0G8hwOJI7HCahzG9CYRERFkZWWFOowuKWiJQ1VrReQGXBIIA55Q1dUicjeQo6pzgBtFZCZQCxQCV3nnForIPbjkA3C3qhZ6P/+AhuG4b3iv4EnoT41E0qd6Z+vHGmNMLxDUBwBVdR7uWYvAsrsCfr4DuKOZc58AnmiiPAcY17GRtkCE/dGD6Fe2A1VFxGbINcb0bqHuHO8WymIzGMweyqvrQh2KMcaEnCWONqhKGGrTjhhjjMcSRxvUJQ0lXiopKbR+DmOMscTRBpKaCUD1no2hDcQYY7oASxxtEJk2DAB/4aYQR2KMMaFniaMNYvsNB0CKtoQ4EmOMCT1LHG2QnJjILk0hssQShzHGWOJog+iIMPLoS1yZPT1ujDGWONpoV9hAUiqsxmGMMZY42igvcjgJtYVQsjvUoRhjTEhZ4mijnbEj3Q+7VoQ2EGOMCTFLHG1UlDjK/bDzi9AGYowxIWaJo43iklLZSj/UEocxppezxNFGR6THs7JuKP4dljiMMb2bJY42OqJvPKv9mYTt3wIVRaEOxxhjQiaoiUNEpovIOhHJFZHbWzhuloioiGR725eKyPKAl19EJnr7FnjXrN/XN5j3UG9Ev3hWq7ca2K6VnfGWxhjTJQUtcYhIGPAQcA4wBrhYRMY0cVwCcBNuKVgAVPVZVZ2oqhOBy4FNqro84LRL6/er6p5g3UOg/onRbI5wU4/YyCpjTG8WzBrHVCBXVTeqajXwAnBBE8fdA/wOqGzmOhd754aUiJDSN4N9vj6w0xKHMab3CmbiGARsC9jO88oOEJHJwGBVndvCdb4NPN+o7Emvmepn0sxariJyrYjkiEhOfn7+IYT/dUf0jWe1ZlqNwxjTq4Wsc1xEfMB9wM0tHHMMUK6qqwKKL1XV8cA073V5U+eq6qOqmq2q2enp6R0S84i+8SytGYLmr4Oaig65pjHGdDfBTBzbgcEB2xleWb0EYBywQEQ2A8cCc+o7yD0X0ai2oarbvX9LgOdwTWKdYkQ/N7JKtA52r+mstzXGmC4lmIljMTBCRLJEJBKXBObU71TV/aqapqqZqpoJLAJmqmoOHKiRzCagf0NEwkUkzfs5AjgPCKyNBNWIvgmuqQpglz3PYYzpncKDdWFVrRWRG4D5QBjwhKquFpG7gRxVndPyFTgJ2Kaqgeu1RgHzvaQRBrwDPBaE8Js0KDmGveH9qAhLIMY6yI0xvVTQEgeAqs4D5jUqu6uZY09ptL0A13wVWFYGTOnQINvB5xOGpyewqWw4Y2zqEWNML2VPjrfTiL7xLK8dCrtXQ01zI4iNMabnssTRTiP6JfBOxQioq4K8z0MdjjHGdDpLHO00PD2ez/1HohIGmz4IdTjGGNPpLHG004h+8ZQSy76kMbDpw1CHY4wxnc4SRzsN7RNLRJiwLmYSbM+BqtJQh2SMMZ3KEkc7hYf5GJYWz6f+MeCvhW2LQh2SMcZ0Kksch+CIvvG8WZwJvgjr5zDG9DqWOA7BmIGJfLXPT83AKdbPYYzpdSxxHILsoSkAbEucAjuX24qAxphexRLHIZgwOJnIMB+f+MeC+mHLJ6EOyRhjOo0ljkMQHRHG+Iwk/lMwCMKjYbM1Vxljeg9LHIfo6Mw+LN9RTl3GMdZBbozpVSxxHKKjM1OoqVPyUqbC7lWwb0uoQzLGmE5hieMQZQ/tgwi8G34yILD8uVCHZIwxncISxyFKio1gVL8E3t8VCcNPheXPgt8f6rCMMSbogpo4RGS6iKwTkVwRub2F42aJiNYvGysimSJSISLLvdfDAcdOEZGV3jX/LCISzHtoSXZmCku37KNuwqWwfxtsWhiqUIwxptMELXGISBjwEHAOMAa4WETGNHFcAnAT8FmjXRtUdaL3ui6g/K/ANcAI7zU9GPG3xdGZfSirruPLpGkQnQzLnglVKMYY02mCWeOYCuSq6kZVrcatHX5BE8fdA/wOaHVVJBEZACSq6iJVVeBp4MIOjLldpmb1AeCzbeVw1GxY+xpU7AtVOMYY0ymCmTgGAdsCtvO8sgNEZDIwWFXnNnF+logsE5GFIjIt4Jp5LV2zMw1IimFQcgyLNxfCpMvc4k4rXwpVOMYY0ylC1jkuIj7gPuDmJnbvBIao6iTgx8BzIpLYzutfKyI5IpKTn59/+AE3Y2pWHxZvLkT7HwX9x8OyfwTtvYwxpisIZuLYDgwO2M7wyuolAOOABSKyGTgWmCMi2apapaoFAKq6BNgAjPTOz2jhmgeo6qOqmq2q2enp6R10S1930sg09pZW8/mmQph8Jez8AjZ/HLT3M8aYUAtm4lgMjBCRLBGJBC4C5tTvVNX9qpqmqpmqmgksAmaqao6IpHud64jIMFwn+EZV3QkUi8ix3miqK4D/BPEeWjV97ADio8L515I811wV3x/euwdUQxmWMcYETdASh6rWAjcA84G1wIuqulpE7haRma2cfhKwQkSWAy8B16lqobfvB8DjQC6uJvJGUG6gjWIiwzh/wgDmrthJqT8CTr4Vtn4Kue+EMixjjAka0V7wl3F2drbm5OQE7fpLtuxj1l8/4fezjmL2pH7wYDZEJ8G1C8Fnz1gaY7onEVmiqtmNy+1brQNMHpLMsPQ4/rVkG4RHwqk/gV0rYG1IW9GMMSYoLHF0ABHhv6YMZvHmfWzML4Xx/wXpR8J7v4a62lCHZ4wxHcoSRweZNXkQYT7hpSV54AuD038OBeth4e9CHZoxxnQoSxwdpG9iNCePTOflpXnU1vnhyHNh4qXwwR9sXXJjTI9iiaMDXXT0YHYXVzFv1S5XcM7vIXU4vHINlBWENjhjjOkgljg60Bmj+zEsPY6HF2xAVSEqHr71BJQXwH+ut2c7jDE9giWODuTzCdedNJw1O4v5YP1eVzhgApzxS/jqDch5IrQBGmNMB7DE0cEumDSQ/onR/HVBbkPhMdfBsFPgrZ9B4cZQhWaMMR3CEkcHiwoP43vTsli0sZBlW70p1n0+uOAhN9rq1evBXxfaII0x5jBY4giCi6YOITE6nIcXbmgoTMqAc34HWz+BRX8JXXDGGHOYLHEEQXxUOFcen8n81btZtX1/w44JF8OoGfDuPZD/VegCNMaYw2CJI0i+d+Iw0uKjuOOVle65DgAROP9+CI+GN2+3UVbGmG7JEkeQJMVG8MuZY1m5fT9//2Rzw474vnDK7bDhXVj/VsjiM8aYQ9WmxCEiN4lIojh/E5GlInJWsIPr7s4d35/Tj+zLH9/6im2F5Q07pl4DaSPhzTugtjp0ARpjzCFoa43ju6paDJwFpACXA/cGLaoeQkS458Jx+ATufHUVB6awD4uAs38DhRvg80dCG6QxxrRTWxOHeP+eC/xDVVcHlJkWDEyO4ZazR7Hwq3xeXR6wyu2IM2HEWbDw91C6J3QBGmNMO7U1cSwRkbdwiWO+iCQA/tZOEpHpIrJORHJF5PYWjpslIioi2d72mSKyRERWev+eFnDsAu+ay71X3zbeQ8hccVwmk4ck88vX1rC3tKphx9m/geoy+PiB0AVnjDHt1NbEcTVwO3C0qpYDEcB3WjrBWzP8IeAcYAxwsYiMaeK4BOAm4LOA4r3A+ao6HrgS+Eej0y5V1Yneq8v/uR7mE37/raMor6rj53NWN+xIGwFjvwFL/g4V+0IWnzHGtEdbE8dxwDpVLRKRy4A7gf2tnDMVyFXVjapaDbwAXNDEcfcAvwMq6wtUdZmq7vA2VwMxIhLVxli7pCP6JnDj6Ucwd8VO5q/e1bDjhJugutTmsTLGdBttTRx/BcpFZAJwM7ABeLqVcwYB2wK287yyA0RkMjBYVee2cJ1ZwFJVDWjj4UmvmepnItJkX4uIXCsiOSKSk5+f30qoneP7Jw9nzIBE7nx1FfvLa1zhgKNg+Omw6GGoqWz5AsYY0wW0NXHUqhsSdAHwoKo+BCQczhuLiA+4D5eImjtmLK428v2A4ku9Jqxp3uvyps5V1UdVNVtVs9PT0w8n1A4TEebj9986ioLSKh58f33DjhNugrI98MVzoQvOGGPaqK2Jo0RE7sB9Sc/1vvQjWjlnOzA4YDvDK6uXAIwDFojIZuBYYE5AB3kG8G/gClU9MOmTqm73/i0BnsM1iXUb4wYlMWtyBk99sqXh2Y6sk2DgJPjk/2wCRGNMl9fWxPFtoAr3PMcuXBL4QyvnLAZGiEiWiEQCFwFz6neq6n5VTVPVTFXNBBYBM1U1R0SSgbnA7ar6cf05IhIuImnezxHAecCqNt5Dl/Hjs0YiAve97c1XJQIn/NBNub52TssnG2NMiLUpcXjJ4lkgSUTOAypVtcU+DlWtBW4A5gNrgRdVdbWI3C0iM1t5yxuAI4C7Gg27jcINB14BLMfVYB5ryz10JQOSYvjuiVn8e9n2hkkQR5/vniZ//7dW6zDGdGmibZhoT0Rm42oYC3AP/k0DblXVl4IaXQfJzs7WnJycUIdxkP0VNZz8h/cZPyiJf1x9jCtc/Sr860q48GGYeHFoAzTG9HoiskRVsxuXt7Wp6qe4ZziuVNUrcP0KP+vIAHubpJgIbjj1CD5cv5ePc71lZsdcAAMmwoLf2BxWxpguq62Jw9foQbuCdpxrmnH5cUNJT4ji8Q+95WRF4PSfQdFWWPpUaIMzxphmtPXL/00RmS8iV4nIVbiO63nBC6t3iAoP45KpQ3h/XT6b9pa5wuGnw9AT3RxW1WWhDdAYY5rQ1s7xW4FHgaO816OqelswA+stLj1mCBFhwtOfbnYFInD6Xe65jsWPhzI0Y4xpUpubm1T1ZVX9sff6dzCD6k36JkZz7vgBvJSTR1lVrSsccox7tuPzx6CuNrQBGmNMIy0mDhEpEZHiJl4lIlLcWUH2dFcdn0lJVS2vLM1rKJx6LezfBl+9GbrAjDGmCS0mDlVNUNXEJl4JqprYWUH2dJOGpDAhI4m/f7K5YbGnkedAYgZ8/mhogzPGmEZsZFQXcdUJmWzIL+PD9d7Q3LBwOPq7sGkh5K8LbXDGGBPAEkcXce74AfRNiOKRDzY0FE6+EsKiXF+HMcZ0EZY4uoio8DCumTaMj3MLWLbVW9QpLg3GzYIvnodK61IyxnQNlji6kEuOGUJybAQPvZ/bUDj1GrfQ03Kbct0Y0zVY4uhC4qLC+e4JWbyzdg9rdng1jEGTYchx8NGf7IFAY0yXYImji7nyuEzio8J5aEFAreOMX0DpLvj0L6EKyxhjDrDE0cUkxUZw+XFDmbdyJxvyS13hkGPhyPPg4/uhtGssg2uM6b0scXRBV5+YRVS4j0cWBoywOuOXUFMBC+8NXWDGGEOQE4eITBeRdSKSKyK3t3DcLBHR+mVjvbI7vPPWicjZ7b1md5YWH8WsyRm8unwH+SVVXuERkP0dyHkS9q5v+QLGGBNEQUscIhIGPAScA4wBLhaRMU0clwDcBHwWUDYGt9TsWGA68BcRCWvrNXuC756YRXWtn2cWbWkoPPk2iIiB135o63UYY0ImmDWOqUCuqm5U1WrgBeCCJo67B/gdUBlQdgHwgqpWqeomINe7Xluv2e0NT4/n9CP78syiLVTWeEvJxveFGX+ELR/Bq/8P/P7QBmmM6ZWCmTgGAdsCtvO8sgNEZDIwWFXntvHcVq8ZcO1rRSRHRHLy87tnh/LV07IoKKvmP8u3NxROuAhO/zmsegnetkUYjTGdL2Sd4yLiA+4Dbg7G9VX1UVXNVtXs9PT0YLxF0B03LJUxAxJ5/MNNHLQ2/Ik/crPnfvogLHo4dAEaY3qlYCaO7cDggO0Mr6xeAjAOWCAim4FjgTleB3lz57Z2zR5FRPjetCzW7ynlg/rJD90OmH4vjJwO7/wCineELEZjTO8TzMSxGBghIlkiEonr7J5Tv1NV96tqmqpmqmomsAiYqao53nEXiUiUiGQBI4DPW7tmT3TeUQPplxjFYx9sPHiHLwzO+R1oHbz369AEZ4zplYKWOFS1FrgBmA+sBV5U1dUicreIzGzl3NXAi8Aa4E3gelWta+6awbqHriAy3Md3Tsjio9y9rMzbf/DOlEzXZLX8Wdi1KiTxGWN6Hzmo7byHys7O1pycnFCHcciKK2s44bfvcdKodB66ZPLBOyv2wQMTYdAUuPyV0ARojOmRRGSJqmY3Lrcnx7uBxOgILj12KG+s3MmWgkYTHcakwEm3woZ3Iffd0ARojOlVLHF0E989IZNwn49HG/d1gJt6PXkozLsFSnZ3fnDGmF7FEkc30TcxmllTBvGvJXkN05DUC4+CbzziksZT51nyMMYElSWObuSaacOoqfPz5Mebvr5z6HFw6b9g/3ZLHsaYoLLE0Y0MS4/n3HEDePrTLewra2KuqswTGpLHAxPg/qPg0VNg3q3gr+v0eI0xPZMljm7mpjNGUFZdyyNN9XWASx5XvQ5TroTBx0BkPHz+KHz+WOcGaozpscJDHYBpn5H9Epg5YSBPfbKZq0/MIj0h6usHDZrsXgCq8MwsePduOHIGJA/++vHGGNMOVuPohm46fQRVtXUHL/TUHBE470+AwtybXSIxxpjDYImjGxqWHs83J2fwj0Vb2F1c2foJKUPhtDth/XxYbQ8JGmMOjyWOburG00ZQ51ceeLeNqwEecx0MnASv/wjevcdWETTGHDJLHN3UkNRYrjguk+c+28qbq3a2foIvDGb9DTKOho/ugwez4W9nw77NQY/VGNOzWOLoxm47ZxQTBidzy79WsDG/tPUTUofDZS/Dj9fCWb+C/C/hb2fBzi+CH6wxpsewxNGNRdSCBAYAAB+oSURBVIWH8ZdLJxMRJvy/Z5ZSXl3bthMT+sPx/w1XvwW+CHhyBmxcENRYjTE9hyWObm5QcgwPXDSJr/aU8JNXVtKu2Y7TR8H33nZDdJ/5Fnz2qI26Msa0yhJHD3DSyHR+dMZIXl2+g6c+2dy+kxMHwnfmwfBT4Y1b4cXLoaIoKHEaY3qGoCYOEZkuIutEJFdEbm9i/3UislJElovIRyIyxiu/1Curf/lFZKK3b4F3zfp9fYN5D93FDacewRmj+/GruWv5fFNh+06OSYGL/wln3gPr3oCHp8GH98Hu1VYDMcZ8TdAWchKRMOAr4EwgD7fs68WquibgmERVLfZ+ngn8QFWnN7rOeOBVVR3ubS8AbvGWmG2T7r6QU1sVV9Zw4YMfU1xZy+v/fSL9k6Lbf5Fti13NY8cyt500BM74OYz/VscGa4zp8kKxkNNUIFdVN6pqNfACcEHgAfVJwxMHNJXFLvbONa1IjI7gkcunUFFdy/XPLaXOfwh/FAw+Gq5dAD/+Es7/M8SlwctXw6vXQ3VZa2cbY3qBYCaOQcC2gO08r+wgInK9iGwAfg/c2MR1vg0836jsSa+Z6mciIk29uYhcKyI5IpKTn59/aHfQDY3ol8BvvjmeJVv28cRHTUy/3laJA9xEiVe/DdNuceuaP3KSq5EYY3q1kHeOq+pDXjPUbcCdgftE5BigXFVXBRRfqqrjgWne6/JmrvuoqmaranZ6enqQou+aZk4YyBmj+/G/b61j897DrCWEhcPpP4Mr50B1OfztTHjtJigvdK/PH3PPgnz6UMcEb4zp8oKZOLYDgVOxZnhlzXkBuLBR2UU0qm2o6nbv3xLgOVyTmAkgIvz6G+OIDPdx28sr8B9Kk1VjWSfBDZ/DcdfD0n/AnyfBH0e55WoLNsD8n8CXcw//fYwxXV4wE8diYISIZIlIJC4JzAk8QERGBGzOANYH7PMBswno3xCRcBFJ836OAM4DAmsjxtMvMZo7Z4zms02FPPf51o65aFQCnP1r+P4HMOxkyP4ufP9D+NEqGDgZXrkW9qztmPcyxnRZQVuPQ1VrReQGYD4QBjyhqqtF5G4gR1XnADeIyBlADbAPuDLgEicB21Q1cMWiKGC+lzTCgHcAW6GoGbOzB/PaFzu55/U1RIQJs7MH00yXUPv0Hweznz647KJn3WqDz18M17wHsX0O/32MMV1S0IbjdiW9ZThuUwpKq7jxhWV8nFvAhRMH8qtvjCc+Kkh/L2z7HP4+A+L7wYk/hImXQcQhDAk2xnQJoRiOa7qA1Pgonv7uMfz4zJHM+WIHMx/86PA7zJszeCpc9oqbC2vuzW7d84W/d81XveAPFGN6C6tx9CKfbijgB88uQUT425XZTBqSEpw3UoVNH8CH/+v+BegzHLK/A8deDz77e8WY7sBqHIbjhqfy8v87nviocC5+bBFvrd4VnDcScZ3nV74GN6+DGfe5ObHeutPNhVVVEpz3NcZ0Ckscvcyw9Hhe+cHxjOqfyPefWcJv5q2lqrYueG+Y0B+OvtolkbN/6+bCevxM2JsbvPc0xgSVNVX1UhXVddwzdw3PfbaVI/sncN/siYwZmBj8N964AP51FVTsg/QjIXMa9BsDtVVQUw4RsTD6fEjKCH4sxpgWNddUZYmjl3v/yz38z8srKCqv5uazRnHNtGGE+TpgyG5L9ufByn/Bpg9h6yKoadxZL5B5Ihw1G4afDklfm6nGGNMJLHFY4mhWYVk1P/33St5YtYupWX24b/YEMlJiO+fN62qgdA9ExLjaRslOWPEifPE87PPm2uoz3D25nnE0DJoMaSPdGur1ygpg00LYtRImXgJpI5p+L9N2RVshabDrrzK9liUOSxwtUlVeXrqdX8xZjQA/nTGabx/dQQ8MHlpAsHuVG5W1cSFs/RSqvMmUw6PdGiKRcSBhsPcrDkysHNcXrnrdrW5Yr7ocwiLdvFumdVsXwRPT4aRb4LQ7Wz/e9FiWOCxxtMm2wnJufekLFm0s5Pjhqfz2m+MZmhoX6rDA74eCXNi+xCWUyv1QXQq11TBwklvBMDIOnprp/kq+aq5LLh/+ERY/DgkD4KRbYcJFEBbR8vvUlEHJLvd+BblQurvhOZSwCEgY6EaJpQ53/TQ96a9yvx8eOxV2LofwGLhxmZsp2fRKljgscbSZ36+8sHgbv523lhq/n+tPOYJrThpGdERY6yeHWv469/S6qtfhXgbjZ8PedW5xquShMOociEt3a42UF7pEtGsVFO+A6iaGCodHg/gAgboq8Nc27Esb6a5/1H9BSmbn3OOO5VC0BUac5Zr46tVUujVT4lKbP1cVaisPPi/QsmfhPz+AU3/qHt6cdCmc/0DDfn/dwc2EpkezxGGJo9127q/gl3PW8ObqXQxKjuGOc49kxvgBoWu+aqs9a+G5b8OAo+C0n7lmK1VY/5ZbEnfPmoZmL3CrHPYfDylD3USOUQkQm+b6SvoMO3jeLb8fyvdC8XaXiFa+BFs+BgQmXAyn/gSSBx8cj6o77uMH3EJZx/+3u257qcJnD8P8n4LWQVQijPsmpI6Aje/D5o+htgIGZcPo82DUDHcP9Z9X3hJ45+ew+UOYfAWceberldWrKoH/mwLJQ9w6LG/c5mprP1gE6SPd9V/6jhsJ942HW665NVZXC0uedL+3U++0ZsNuwhKHJY5D9smGvdz92hq+3FXC1Mw+3HX+GMYNSgp1WIenphLK8l2SiEk+vGsVbYXPHnFrk4B7Qn7YKdBvrKupzL0ZvnrTfcEXbXE1lrHfcFPUD5py8LX25romt8bNQ9Xl8PoPYcU/4cjz3MzEK/8Fa/7jhjGnjoDhp7la1Lp5DUv/xqZCxlQXx7q5LiEecQasfNHVus7+DQw9wZ33/m/go/vge+9BxhQozYc/T3T3MuwUePN2d37pLhfDt56E8MjWfz8bF7pz93irRk+8FGY+aDMIdAOWOCxxHJY6v/LPxdv441vrKCyvZvaUwfzP9FGkxkeFOrSuo2gbLLgXvngO1N9QHh7jFsM65jqXrD59CHKedM1ig6a4JFC8E1a9DPnetPRpI91f9r4w14y2e5WrEZz6U5h2c8OXblWJeyUObBTLVtjwnluxcdtnbuTasde52k5UgmvumvPfsGvFwecddRF885GG7YW/h/d/7X4ecTbMegy+eAHe+B+3fcrtbjTbrhWupnL091ziAzfsev5PXHJLHuKS1K5VsPBe97uYfq9by+XDP0LeYtcsln01RCe6JreVL8FX8912Qn+XtKrLoLwAKovAFwGRsRAZD2Nmur6uzlRX45Jh/6MO7ueqqXAJPnkIDDm+W0/0aYnDEkeHKK6s4f/eXc+TH28mMSaCey4Yx4yjrPP0IJX7XXPZ7tWu32TSpV9vmqosdkOOP3/UdcCD+5IZ+w3Xj7LpA9jyiSvvNxb6jYOxF7phyR2lrhZy34GSHVC21yWg42+E+IAVM6tK4dlvufc9+faGhJXzBLz+o4bjIuJcf1JcXzcIoabMJR1VmPZjl7AiYtz2/J/Aor+4mtD2HAiLclP15y2G6CRXI1r/tmtOTB7qknDJzoa+pagkiEly/S3VZW6QhL8WRs90ibWmHFb/281SkD7KNcmlDm/5d7F7Dbx3D+R/6T6HYSe7Pqs9a1yyqyxyfUojz3b3uuIFd39FW2Dct2Dmn13CLN3jlhbY7n3fRMS6PwAGT4WBE2HAJJe4/bXgr3HJp7YK6qohcdDXa3AFG9w1B01punZXW+3+UNmxHI6cAcNO7dBmQEscljg61Fe7S7j5xS9YuX0/M44awO3Tj2Rwn0569qMn8fthx1L3F3Xjp+X9dYB03SadLZ+4L/QBEyEly33xv3s3bPnI7T/yPFfLSBl68HmqXrPbi246muNvhPi+bsTch/e52QVGnev2DT7G/TXv90PVfle7aNy3UlnsEtEnDzYMbvCFw9DjYftS98V8zPfddv6XbgCFv84l8z5ZsPkjWP6c6zMaepwbjlxZ1HD9yHiX9Mry3bDu2FTvvie4JPP5I5A2ytUq37jdHXfBg+56ue+4ml/BelqVMBBOvhUmXe6S4YJ7XfOn1rlklTXN/T6Sh7hX/pfwwR9c7TIsyv3BEde3YfBHZJxLUuNmHfL6OJY4LHF0uNo6P498sJH73/mKmjpleHocp4zqy7nj+zN5SErX70Q3HU+1oaaUeULLx9bVtK+DvTVlBbD07+5L88jz3JdlyW5Xk1j2DAee9Ukc5J7/Kc5ztZmwSJh6rWsCjO3jksqula622He0q/WAS4xr57jEk/0dl9xEYMP78PLVrgktvj9c/Lx7UDVQRRHs/MJdt7bSJTZfmPvCD48EBJY/65oVk4e6xFGxD6Zc5WoRmxa6BFS48eDrDpzkallZJ7la2ooXXG21qqShufSGJZB2xCH9SkOSOERkOvAAbrW+x1X13kb7rwOuB+qAUuBaVV0jIpnAWmCdd+giVb3OO2cK8HcgBpgH3KSt3IQljuDaVljOW2t2s2DdHj7bWEh1nZ8RfeO5aOoQZk0eRHJsGzpQjQmmvbne/GijXJ8JuGaeoq1uO77v4V1/f54bgXb09w59nrX6kX8f/K+rLZx5txsZGKiqFPZvc/1pEdGuGaypP9Dqh11Xl0F08iE3X3V64hCRMOAr4EwgD7cG+cWquibgmERVLfZ+ngn8QFWne4njdVUd18R1PwduBD7DJY4/q+obLcViiaPzlFbV8voXO3h+8Ta+2FZETEQYF00dzPemDWNQcjPPDhhjuqTmEkcwB1NPBXLr1wwXkReAC4ADiaM+aXjiOFCXbJqIDAASVXWRt/00cCHQYuIwnSc+KpyLpg7hoqlDWLOjmMc/2sg/Pt3C059uYdbkQdxy9ij6JnTfUSbGmOCuxzEI2BawneeVHURErheRDcDvcTWJelkiskxEForItIBr5rV2Te+614pIjojk5OfnH859mEM0ZmAi982eyAf/cypXHDeUfy/bzun/u5DHP9xITZ2/9QsYY7qkkA/XUNWHVHU4cBtQP6PaTmCIqk4Cfgw8JyLtWixCVR9V1WxVzU5PT2/9BBM0A5Nj+Pn5Y3nrRyeTnZnCr+au5ew/fcB/lm+nzt/zB2cY09MEM3FsBwLnXsjwyprzAq7ZCVWtUtUC7+clwAZgpHd+YM9Ta9c0XUhWWhxPfmcqf7sym8hwHze9sJyz7/+A177Ygd8SiDHdRjATx2JghIhkiUgkcBEwJ/AAEQlcOGEGsN4rT/c61xGRYcAIYKOq7gSKReRYcWM9rwD+E8R7MEFw+uh+zLtxGg9dMhkB/vv5ZUx/4ANeX2EJxJjuIGid46paKyI3APNxw3GfUNXVInI3kKOqc4AbROQMoAbYB1zpnX4ScLeI1AB+4DpVLfT2/YCG4bhvYB3j3ZLPJ8w4agDTx/Vn3sqdPPDuem54bhnD0r/iwomDmHHUAIanx4c6TGNME+wBQNMl1PmVuSt38synW1i8pRBVGDcokTtnjOHYYS1ME26MCRp7ctwSR7exa38lb6zayRMfb2JbYQX/NSWDO84dTZ84e5DQmM5kicMSR7dTUV3Hn99bz2MfbCQ2MoyTRqZzwhFpnHhEms2LZUwnsMRhiaPbWrerhEcWbuCj3L3sKakCYGS/eM4a05+zxvZj/KAkmxfLmCCwxGGJo9tTVTbkl7Lwq728s2Y3n28upM6vTB6SzI2nj+DkkemWQIzpQJY4LHH0OPvKqnl9xQ4eXriR7UUVTMhI4oQj0shMjWNIaiwTByd3j3XSjemiLHFY4uixqmv9vLw0jyc/3sSG/LIDT6MnRIdzwcSBzM4ebM1ZxhwCSxyWOHqF2jo/O4oqWb+nhNe+2MEbq3ZRVesnMzWWM0b348wx/TiyfyLRkT4iw3yWTIxpgSUOSxy90v6KGuau2Mn81bv4dEMB1QGTK4b5hLEDE7nyuEzOmzCAqHBr1jImkCUOSxy9XkllDR/n7mVHUSUVNXWUVtXy9prd5O4pJTUukpNHpZMcE0lSTAT9EqMY2T+Bkf0SiI8K5uoDxnRdoViPw5guJSE6gunjBhxU9j9nj+Lj3AKe+nQzizYUsL+ihrLquoOOGT0gkWtPyuL8owYSHhbyCaWNCTmrcRjTSH0/yZe7ilm3q4TXV+xk3e4SBveJ4RuTMvD7ldKqWmr9fvolRNM/KZpByTEM7hPLgKRoSy6mx7CmKksc5hD5/cq7X+7hwfdz+WJbET5xKx36fEJRec1Bx4b5hP6J0fh84PdDeJhw8sh0vjk5gwkZDSO7VNU65k2XZ4nDEofpAJU1dUSFN4zGqqypY3dxJduLKsgrrGBrYTk79le4RZAFiitq+WB9PtW1fob0iSUq3EdhWTX7yquJiwwnNT6S1PgohvaJ5Yh+8Yzsm0BKXAQigk+EoX1iSbE5ukyIWB+HMR2g8QOF0RFhDE2NY2hqHAxv+pziyhreWLmTt9fsJtzn4+isSFJiIyivrqOgtJr8kio+3VjAK8u+viZZmE+YmtmHs8f247jhaQzpE0tMpIuhsqaOvH3l1NQpw9PjiQxvuolMVanzqzWhmQ5jNQ5juojiyhpy95RSWlmL3/uyX7a1iDdX7yJ3T+mB49ITogj3CbuKK6n/3zfcJxzRN56MlBiqav1U1tRRWlVHYVkVhWXV+ES46vhM/t8pw0mOtRqMaZuQNFWJyHTgAdxCTo+r6r2N9l8HXA/UAaXAtaq6RkTOBO4FIoFq4FZVfc87ZwEwAKjwLnOWqu5pKQ5LHKa725BfyuodxWwrLGdLQRm1fmVonziGpsbi8wlf7ixmzc5idu2vJCYyjOjwMOKiwkiNi6JPfCQ7iiqY88UOEqLCuXjqEArLqlm7q5gtBeVkpMRyZP8EjugbT0xEGCKgCvvKq9m1v5K9pVWkxkcxPD2e4elxpMRFEhnmIzLcR0psJOkJUYT5Gvpr6ldx9PmsD6e76/TE4S39+hVwJpCHW0r2YlVdE3BMoqoWez/PBH6gqtNFZBKwW1V3iMg4YL6qDvKOWwDcoqptzgSWOIyBtTuL+cP8dbz35R5S4yIZMzCRoamx5O2rYN2uEnburzzoeJ+42k1afBT5JVUHZiZuLNwn9EuMJiJMKKqoobiihogwH1lpcWSmxpES55rlyqpqqar1B1xfiAjzEREmRIb7iI0MJy4yjPjocPonRtMvKZr+idGkxkWSHBtJZLiPypo69hRXUVheTd+EKG8gQtsTlKqytbCc2Mhw0hOiDu0X2YuEoo9jKpCrqhu9AF4ALgAOJI76pOGJw3UpoqrLAspXAzEiEqWqTf+Xa4xp1egBiTxx1dGUVdUSGxn2tVFdZVW11NT5DzR/JcZEHFST2F9Rw8b8Ukq946pr/ewtrWZHUQU7iiqoU0iJjSApJoKK6jo2F5Tx1Z4SiitqiY8KIzYynMhwH/Vv6/crNXVKTZ2fqlo/5dV1lFfXUt7oOZp6UeG+gxIPQExEGENTYw+McvMJ1NQplTV1VNbUkRwbydA+sQzuE8vO/RV8nFvA9qIKIsN8XHLMEH5w6nD6JkQfuF6d383AvHxrEXvLqhjRN4FR/RLISIn5WoJSVSpq6hAEnw/Cfb6Dfl89WTATxyBgW8B2HnBM44NE5Hrgx7hmqdOauM4sYGmjpPGkiNQBLwO/0iaqTSJyLXAtwJAhQw71HozpceKaeRK+ufJ6STERTBqSEoyQDlJT52dPSRW79lewu9j10ewrq6akqpakmAj6JkSREhvJruJKNuaXsbmgjMqaOvyq+P0QHeEjJTaCqPAwCsuqWbSxgH8v305CVDjHD0/jupOHsXpHMf9YtIUXFm/l2GGplFfVUVxZQ96+Ckqrar8WU0SYEB8VTlyUS37FFTUUlddQ62/46gn3CaeM6svs7AxOPbIvO4oqeO/LPXycu5f8kipKKmspraqlT1wkQ/rEMqRPLH0To9xsBbER7CyqYPm2Ilbk7UcExgxMYuzARJJiIthbUkV+aRVR4T6mZqUyNbMPSbERB/3O9pVVU1BWze7iSjbvLWPT3jI27i3jgYsmdfjqmcFsqvoWMF1Vv+dtXw4co6o3NHP8JcDZqnplQNlYYA6uH2ODVzZIVbeLSAIucTyjqk+3FIs1VRnTu1XV1n2tRrB5bxn/914ua3cWkxgTTmJ0BP0So5kwOJmJg5PpmxhF7p5SvtpVwpbCcsqqaimtrKWqzk9idAQpsRHER4cjCH5VCkqreW3FDvJLqoiJCKOixtWchqXFMbhPLPHR4cRHhlNQVsXWwnK2FpZTWXNwDapvQhQTBicDsGZHMduLKg7sS4qJoKKmjupaPyLQPzHaq6nVfu06AAlR4QxLj+NP357IsPT4Q/q9haKP4zjgF6p6trd9B4Cq/raZ433APlVN8rYzgPeA76jqx82ccxWQ3VwyqmeJwxjTGWrq/Cxcl8+7X+5mZL8ETjuyrxuq3QRVpay6jn1l1RSV15AaH8mApOiDmhCLyqspq64jLT6SqPAwKmvq+GJbEYs2FrK1sJyYyPq+oXD6xEeSFucGK2SmxZEaF3nYD5mGoo9jMTBCRLKA7cBFwCWNghqhquu9zRnAeq88GZgL3B6YNEQkHEhW1b0iEgGcB7wTxHswxpg2iwjzccaYfpwxpl+rx4q45q/4qHAG92n6mOTYSJJjG7ajI8I4ZlgqxwxL7aCID03QEoeq1orIDcB83HDcJ1R1tYjcDeSo6hzgBhE5A6gB9gH1zVQ3AEcAd4nIXV7ZWUAZMN9LGmG4pPFYsO7BGGPM19kDgMYYY5rUXFOVzUFgjDGmXSxxGGOMaRdLHMYYY9rFEocxxph2scRhjDGmXSxxGGOMaZdeMRxXRPKBLYd4ehqwtwPD6S564333xnuG3nnfds9tM1RV0xsX9orEcThEJKepccw9XW+87954z9A779vu+fBYU5Uxxph2scRhjDGmXSxxtO7RUAcQIr3xvnvjPUPvvG+758NgfRzGGGPaxWocxhhj2sUShzHGmHaxxNECEZkuIutEJFdEbg91PMEgIoNF5H0RWSMiq0XkJq+8j4i8LSLrvX+Dv9h0JxORMBFZJiKve9tZIvKZ93n/U0Q6dqHmLkBEkkXkJRH5UkTWishxPf2zFpEfef9trxKR50Ukuid+1iLyhIjsEZFVAWVNfrbi/Nm7/xUiMrk972WJoxkiEgY8BJwDjAEuFpExoY0qKGqBm1V1DHAscL13n7cD76rqCOBdb7unuQlYG7D9O+BPqnoEbmGxq0MSVXA9ALypqkcCE3D332M/axEZBNyIW2J6HG4BuIvomZ/134Hpjcqa+2zPAUZ4r2uBv7bnjSxxNG8qkKuqG1W1GngBuCDEMXU4Vd2pqku9n0twXySDcPf6lHfYU8CFoYkwOLw17WcAj3vbApwGvOQd0hPvOQk4CfgbgKpWq2oRPfyzxq10GuMtPR0L7KQHftaq+gFQ2Ki4uc/2AuBpdRYBySIyoK3vZYmjeYOAbQHbeV5ZjyUimcAk4DOgn6ru9HbtAlpfRLl7uR/4H8DvbacCRapa6233xM87C8gHnvSa6B4XkTh68GetqtuB/wW24hLGfmAJPf+zrtfcZ3tY32+WOAwAIhIPvAz8UFWLA/epG7PdY8Zti8h5wB5VXRLqWDpZODAZ+KuqTgLKaNQs1QM/6xTcX9dZwEAgjq835/QKHfnZWuJo3nZgcMB2hlfW44hIBC5pPKuqr3jFu+urrt6/e0IVXxCcAMwUkc24JsjTcG3/yV5zBvTMzzsPyFPVz7ztl3CJpCd/1mcAm1Q1X1VrgFdwn39P/6zrNffZHtb3myWO5i0GRnijLyJxHWpzQhxTh/Pa9v8GrFXV+wJ2zQGu9H6+EvhPZ8cWLKp6h6pmqGom7nN9T1UvBd4HvuUd1qPuGUBVdwHbRGSUV3Q6sIYe/FnjmqiOFZFY77/1+nvu0Z91gOY+2znAFd7oqmOB/QFNWq2yJ8dbICLn4trCw4AnVPXXIQ6pw4nIicCHwEoa2vt/guvneBEYgpuSfraqNu546/ZE5BTgFlU9T0SG4WogfYBlwGWqWhXK+DqaiEzEDQiIBDYC38H9AdljP2sR+SXwbdwIwmXA93Dt+T3qsxaR54FTcNOn7wZ+DrxKE5+tl0QfxDXblQPfUdWcNr+XJQ5jjDHtYU1Vxhhj2sUShzHGmHaxxGGMMaZdLHEYY4xpF0scxhhj2sUShzFdnIj8//buXzWqIAzD+POKIEoEG20sFLURQQOChSII3oCFNv65Ahs7EbTxBqwEU0ZMIYLpxRSBFBJFYuMVpLIRIYUg8bOYWYlauEc2WYvn1+2cYdgpDt+es8z7XRol+Er/AwuHJGkQC4c0IUluJllNspZkrvf72EjyqPeDWEpysM+dTfKm90JY3NIn4USS10k+JHmf5HhffmZLH42FfoBLmgoLhzQBSU7STidfqKpZYBO4QQvVe1dVp4Bl2mlegKfA3ao6TTu1PxpfAB5X1RngPC3RFVpq8R1ab5hjtLwlaSp2/32KpDFcBs4Cb/vDwF5aoNx34Hmf8wx42ftiHKiq5T4+D7xIsh84XFWLAFX1FaCvt1pV6/3zGnAUWNn+bUl/snBIkxFgvqru/TKYPPht3r9m/GzNUdrEe1dT5KsqaTKWgKtJDsHPXs9HaPfYKIX1OrBSVV+Az0ku9vFbwHLvwLie5EpfY0+SfTu6C2kM/mqRJqCqPia5D7xKsgv4BtymNUs61699ov0PAi3i+kkvDKOUWmhFZC7Jw77GtR3chjQW03GlbZRko6pmpv09pEnyVZUkaRCfOCRJg/jEIUkaxMIhSRrEwiFJGsTCIUkaxMIhSRrkByePvuXF01QiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "AqXvOKud3Uj_",
        "outputId": "205ade80-facc-4f12-bfb1-d944ed73ef9f"
      },
      "source": [
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('Accuracy history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'])\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kREzhjPPCF5y"
      },
      "source": [
        "Hyper parameter\n",
        "this help to find the right combination of neurons and layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH7mWwva3jPG"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import  GridSearchCV\n",
        "from keras.layers import ReLU , LeakyReLU , ELU , Dropout , Dense , Activation , Embedding , BatchNormalization, Flatten\n",
        "from keras.activations import sigmoid,relu\n",
        "\n",
        "def create_model(layers):\n",
        "  model = Sequential()\n",
        "  for i , nodes in enumerate(layers):\n",
        "    if i ==0:\n",
        "      model.add(Dense(nodes,input_dim = X_train.shape[1]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(Dropout(0.3))\n",
        "    else:\n",
        "      model.add(Dense(nodes))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(Dense(units=1,activation='sigmoid',kernel_initializer='glorot_uniform'))\n",
        "\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpS5x0N-Iq1K"
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta6JvsmPNq_S"
      },
      "source": [
        "\n",
        "#here i am specifing how many layers i want in first trial 1 layer with 20 neurons \n",
        "# second on specifies 2 layers with 40 ann 20 neurons resp.. and so on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "025UAvrJJcwS"
      },
      "source": [
        "layer = [[10,20],[20,30]]\n",
        "activation = ['relu']\n",
        "param = dict(layers = layer,batch_size = [128,256],epochs = [30])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qn498vIgKiKx",
        "outputId": "d0a0d8a8-6433-4705-d71b-c871ac702354"
      },
      "source": [
        "grid = GridSearchCV(estimator=model,param_grid=param ,cv = 5)\n",
        "grid_result = grid.fit(X_train,y_train)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 0.8158 - accuracy: 0.3231\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.7119\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7842\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.7912\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7948\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7939\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.8011\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.8038\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8063\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7911\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7955\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7974\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8007\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8030\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8020\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7936\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7933\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7968\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.8101\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8113\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8061\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8073\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8025\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8080\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8067\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8085\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8010\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8086\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.8112\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8137\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8106\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 1s 1ms/step - loss: 0.7025 - accuracy: 0.6137\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.7609\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.7853\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7827\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7953\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.8059\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7928\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.8085\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8097\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8024\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.8117\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.8061\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8016\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8133\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8107\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8109\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8175\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8135\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.8107\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8101\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.8120\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8198\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8132\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.8125\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8180\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8187\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8288\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8110\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8180\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8173\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8175\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6612\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7703\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7879\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7907\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7944\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7853\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7872\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7973\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7880\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7913\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7949\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7929\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7933\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.8037\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8007\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.8020\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8113\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8030\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8132\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8163\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8154\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8109\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.8147\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.8079\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8191\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8186\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8222\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8243\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8073\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8275\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8487\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 0.7938 - accuracy: 0.4598\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7359\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7786\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7875\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7962\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7910\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7907\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7924\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7947\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.8018\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7966\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.8001\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7988\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8049\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8021\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7973\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7947\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8083\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8051\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8051\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.8111\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.8107\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8080\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8193\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8147\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8168\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8133\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8234\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8226\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8280\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8194\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7942\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7912\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7959\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8002\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7986\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7931\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7927\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7926\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8010\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7939\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7972\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8005\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.8129\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8085\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8120\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7973\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8032\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8160\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8013\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8163\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8009\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.8132\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8151\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8198\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8177\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8078\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.8167\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8198\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8165\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8217\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8288\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 0.6799 - accuracy: 0.6048\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7820\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7933\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7934\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8048\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8015\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7903\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8042\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8122\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8147\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8031\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8163\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8106\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8085\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8203\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8158\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8100\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8248\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8229\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8264\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8380\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8237\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8307\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8299\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8377\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8246\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8418\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8389\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8422\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8358\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8469\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5623\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7871\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7919\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7989\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8040\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8121\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8045\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8128\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8019\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8169\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8217\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8113\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8144\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8195\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8142\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8280\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8259\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8285\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8292\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8249\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8342\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8298\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8314\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8327\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8338\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8319\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8390\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8432\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8385\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8464\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8562\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.7361\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7921\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7873\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8066\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7947\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7978\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8006\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8019\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8079\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8155\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8105\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8165\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8105\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8262\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8224\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8253\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8233\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8253\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8256\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8174\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8249\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8298\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8375\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8375\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8280\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8313\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8284\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8391\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8408\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8362\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8625\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 0.6463 - accuracy: 0.6531\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7966\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7957\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7938\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8010\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8020\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8137\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8086\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8080\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8180\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8177\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8195\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8247\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8233\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8260\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8267\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8276\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8222\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8289\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8353\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8451\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8366\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8450\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8381\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8307\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8460\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8454\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8446\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8405\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8446\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8487\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 0.8621 - accuracy: 0.3761\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7390\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7739\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7980\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7836\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8028\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7939\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8026\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8021\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8024\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8125\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8090\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8153\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8076\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8243\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8037\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8079\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8204\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8189\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8159\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8233\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8232\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8196\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8235\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8238\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8325\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8349\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8292\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8288\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8394\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8375\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.7416 - accuracy: 0.5154\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6605\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.7372\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7751\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7914\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7897\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7955\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7983\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7984\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7986\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7860\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8061\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7946\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7914\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7983\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8006\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7906\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7901\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8044\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7967\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8047\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8032\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8070\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7975\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8028\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8091\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8072\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8092\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8057\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8205\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8094\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7384\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7921\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7983\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7906\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7919\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8045\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7974\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7997\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7987\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8015\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7939\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8022\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8056\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7996\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7947\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8021\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8103\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8087\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8086\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7982\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8102\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8088\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8124\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8115\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8148\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8120\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8180\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8070\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8135\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8164\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8169\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.7776 - accuracy: 0.4482\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6706\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.7391\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7778\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7820\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7936\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7901\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7801\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7896\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7865\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7878\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7944\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7955\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7992\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.8000\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7980\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7957\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8009\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8099\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8010\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8115\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7963\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8033\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8046\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8005\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8128\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8081\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7979\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8123\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8043\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8306\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 1s 2ms/step - loss: 0.7021 - accuracy: 0.5715\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6862\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7604\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7698\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7797\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7920\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7970\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7927\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7917\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8010\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7985\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7991\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7938\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7945\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7992\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8057\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7925\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7994\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7979\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8060\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8081\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7993\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8036\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8018\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7998\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8047\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8031\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8050\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8105\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8101\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8050\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6889\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7545\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7879\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7927\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7958\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7990\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7904\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7924\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7939\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7958\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7912\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8010\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8024\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7989\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8013\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7916\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7992\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7918\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8033\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7984\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8021\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8041\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7978\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7866\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8032\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7968\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8080\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8000\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7950\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8002\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8025\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7507\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7944\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7865\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7936\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7961\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8029\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7998\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.8032\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7971\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7922\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8012\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7936\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7971\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8020\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8040\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8030\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7965\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8130\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8145\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8161\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8185\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8129\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8283\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8262\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8227\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8356\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8348\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8370\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8294\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8232\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8425\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.7282 - accuracy: 0.5136\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.7168\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7750\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7939\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7945\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7982\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7927\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7951\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7974\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8086\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7932\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7950\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8029\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8034\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7937\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8043\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7973\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8000\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8125\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8044\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8087\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7955\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8130\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8045\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8184\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8146\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8049\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8144\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8116\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8209\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8394\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.7551\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7838\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7929\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7946\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7925\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7917\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7961\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8010\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7881\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8019\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7960\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.8068\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7945\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.8018\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7974\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8003\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8013\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8047\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8046\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8011\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7963\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8054\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8019\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8110\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8079\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8114\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8101\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8071\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8065\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8196\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8406\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6907\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7809\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8017\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7937\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.8074\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8024\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8028\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7985\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8108\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8097\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8005\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8139\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8240\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8116\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8144\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8098\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8234\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8184\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8218\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8153\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8225\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8229\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8326\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8233\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8253\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8206\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8263\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8199\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8265\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8186\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8363\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6700\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7808\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7859\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7928\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8016\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.8003\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.8006\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8042\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7964\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8017\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8100\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8053\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7990\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7983\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.8077\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8120\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8053\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8091\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8090\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8163\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8185\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8102\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8208\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8158\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8284\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8268\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8211\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8281\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8192\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8222\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-195902239fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fda283f86d0>, as the constructor either does not set or modifies parameter layers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z-oGB6nMpA4"
      },
      "source": [
        "model = create_model(layers=[10 , 20] , activations= 'relu')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKt9Gk7k81Od",
        "outputId": "78353f63-dc38-4700-fa87-5852a88ecba5"
      },
      "source": [
        "model.fit(X_train,y_train,batch_size= 10,epochs = 20)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.4795 - accuracy: 0.7965\n",
            "Epoch 2/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.8083\n",
            "Epoch 3/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8129\n",
            "Epoch 4/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4326 - accuracy: 0.8139\n",
            "Epoch 5/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4340 - accuracy: 0.8114\n",
            "Epoch 6/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.8116\n",
            "Epoch 7/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.8138\n",
            "Epoch 8/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4252 - accuracy: 0.8142\n",
            "Epoch 9/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4253 - accuracy: 0.8109\n",
            "Epoch 10/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4198 - accuracy: 0.8167\n",
            "Epoch 11/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4206 - accuracy: 0.8142\n",
            "Epoch 12/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4171 - accuracy: 0.8165\n",
            "Epoch 13/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4163 - accuracy: 0.8133\n",
            "Epoch 14/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4132 - accuracy: 0.8219\n",
            "Epoch 15/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8165\n",
            "Epoch 16/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4188 - accuracy: 0.8177\n",
            "Epoch 17/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4145 - accuracy: 0.8200\n",
            "Epoch 18/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4129 - accuracy: 0.8248\n",
            "Epoch 19/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4124 - accuracy: 0.8200\n",
            "Epoch 20/20\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda1d1e7e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "BAyWqRjJ-Q4-",
        "outputId": "9c834bdc-da55-497c-952b-dee28189fff5"
      },
      "source": [
        "check_params(\n",
        "    params\n",
        ")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-4c98398b451c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m check_params(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'check_params' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZbroJILeBfw5",
        "outputId": "a29d5f96-cd65-417c-c4c8-bf31f6e5530a"
      },
      "source": [
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n",
        "from keras.activations import relu, sigmoid\n",
        "\n",
        "\n",
        "\n",
        "def create_model(layers):\n",
        "    model = Sequential()\n",
        "    for i, nodes in enumerate(layers):\n",
        "        if i==0:\n",
        "            model.add(Dense(nodes,input_dim=X_train.shape[1]))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Dropout(0.3))\n",
        "        else:\n",
        "            model.add(Dense(nodes))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Dropout(0.3))\n",
        "            \n",
        "    model.add(Dense(units = 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid')) # Note: no activation beyond this point\n",
        "    \n",
        "    model.compile(optimizer='Adamax', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    return model\n",
        "    \n",
        "model = KerasClassifier(build_fn=create_model)\n",
        "\n",
        "\n",
        "layers = [[20], [40, 20], [45, 30, 15]]\n",
        "activations = ['sigmoid', 'relu']\n",
        "param_grid = dict(layers=layers, batch_size = [128, 256], epochs=[1])\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 1ms/step - loss: 0.8793 - accuracy: 0.4219\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.5194\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6313\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.7044\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.7926 - accuracy: 0.4790\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6144\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.8979 - accuracy: 0.4150\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.5219\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 1.0260 - accuracy: 0.3589\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.8298 - accuracy: 0.4456\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.7407 - accuracy: 0.4628\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7550\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.5424\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7887\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6403\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.8156\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.6792\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7894\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.7482 - accuracy: 0.4752\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7937\n",
            "50/50 [==============================] - 1s 1ms/step - loss: 0.6053 - accuracy: 0.7446\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7881\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 0.6978 - accuracy: 0.5613\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7912\n",
            "50/50 [==============================] - 1s 1ms/step - loss: 0.6421 - accuracy: 0.6467\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8131\n",
            "50/50 [==============================] - 1s 1ms/step - loss: 0.7194 - accuracy: 0.5489\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7900\n",
            "50/50 [==============================] - 1s 2ms/step - loss: 0.6415 - accuracy: 0.6407\n",
            "13/13 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7969\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7975 - accuracy: 0.4380\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5506\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.8910 - accuracy: 0.4527\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.7610 - accuracy: 0.5213\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.8483 - accuracy: 0.4749\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.7291 - accuracy: 0.5375\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5940\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.7013\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6951\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7400\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.7774 - accuracy: 0.4424\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.7219\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.6084\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7663\n",
            "25/25 [==============================] - 1s 2ms/step - loss: 0.8828 - accuracy: 0.3499\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6431\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.5308\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7763\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.5968\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7744\n",
            "25/25 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.6897\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.7881\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.8363 - accuracy: 0.3604\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6756\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.7583\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8131\n",
            "25/25 [==============================] - 1s 3ms/step - loss: 0.8201 - accuracy: 0.4130\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7550\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6675\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-e795d8ae6ab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fda27c34950>, as the constructor either does not set or modifies parameter layers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqs6VU0UCaVg",
        "outputId": "0b5b46b2-83f1-450f-c1ab-e522f2cbd04a"
      },
      "source": [
        ""
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.16958176, -0.46460796,  0.00666099, ...,  1.74309049,\n",
              "         1.09168714, -1.09168714],\n",
              "       [-2.30455945,  0.30102557, -1.37744033, ..., -0.57369368,\n",
              "        -0.91601335,  0.91601335],\n",
              "       [-1.19119591, -0.94312892, -1.031415  , ..., -0.57369368,\n",
              "         1.09168714, -1.09168714],\n",
              "       ...,\n",
              "       [ 0.9015152 , -0.36890377,  0.00666099, ..., -0.57369368,\n",
              "        -0.91601335,  0.91601335],\n",
              "       [-0.62420521, -0.08179119,  1.39076231, ...,  1.74309049,\n",
              "         1.09168714, -1.09168714],\n",
              "       [-0.28401079,  0.87525072, -1.37744033, ..., -0.57369368,\n",
              "         1.09168714, -1.09168714]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfRJ8RNRD5HK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}